{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62a7cea5-ae0a-4f1c-90af-90d545e452c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mb7336/miniforge3/envs/sandbox/lib/python3.11/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/Users/mb7336/miniforge3/envs/sandbox/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <EB3FF92A-5EB1-3EE8-AF8B-5923C1265422> /Users/mb7336/miniforge3/envs/sandbox/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/Users/mb7336/miniforge3/envs/sandbox/lib/python3.11/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/mb7336/miniforge3/envs/sandbox/lib/python3.11/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/mb7336/miniforge3/envs/sandbox/lib/python3.11/lib-dynload/../../libjpeg.9.dylib' (no such file), '/Users/mb7336/miniforge3/envs/sandbox/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from sklearn.metrics import balanced_accuracy_score, precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.metrics import f1_score as f1\n",
    "from sklearn.metrics import matthews_corrcoef as mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e5af6f9-1495-4b1e-b8d6-6e212b16c39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "motn = pd.read_csv('../data/freedom_test.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "motn = motn[~motn['text'].isna()]\n",
    "motn.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadd84f3-2293-426c-8f15-364962a1e9eb",
   "metadata": {},
   "source": [
    "# Llama 3 8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e4271dc-de75-4376-bad8-a0101ce39b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "547745c36b9b4af6949d583b567fc08a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"mps\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380f9b5d-6089-40cd-b83a-1eaaad38f0a4",
   "metadata": {},
   "source": [
    "No Logit Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59b4812-d7b1-41dc-90b8-d48b6130356f",
   "metadata": {},
   "source": [
    "# Freedom and Rights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "018420a7-7310-4dd6-b8c3-67302bdb19ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = \"\"\"You are a classifier that determines if a survey answer is about freedom and rights. The survey answer I will show is a response to the question \"What does democracy mean to you?\" \n",
    "\n",
    "Answers about freedom and rights reference \"freedom\" or \"liberty\" in the abstract, or reference a particular freedom such as the freedom to express one's opinion, freedom of religion, or other rights mentioned in the Bill of Rights. They may also contain references to freedom from government, freedom of speech, the Second Amendment, references to civil rights or substantive rights, and references to capitalism or free enterprise. \n",
    "However, the answer is not about freedom and rights if the answer is about voting rights the \"right\" to vote, or anything having to do with voting.\n",
    "I will show you an answer to the question. Read the answer and then determine if the answer is about freedom and rights or not. Here is the respondent's answer:\n",
    "{}\n",
    "If the answer is about freedom and rights, return 1. If it is not about freedom and rights, return 0. Do not explain your answer, and only return the number.\n",
    "\"\"\"\n",
    "# change prompt to only voting != freedom and rights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "513b7a34-108f-423d-a2b4-05f8c8764fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikeb\\.conda\\envs\\sandbox\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mikeb\\.conda\\envs\\sandbox\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1.', '0', '1'}\n",
      "CPU times: total: 24min 31s\n",
      "Wall time: 25min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = freedom\n",
    "res = []\n",
    "for doc in data['text']:\n",
    "    messages = [\n",
    "        #{\n",
    "            #\"role\": \"system\",\n",
    "            #\"content\": system_message,\n",
    "        #},\n",
    "        {\"role\": \"user\", \"content\": user_message.format(doc)},\n",
    "    ]\n",
    "    prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    outputs = pipe(prompt, max_new_tokens=2, do_sample=False, return_full_text = False, pad_token_id=pipe.tokenizer.eos_token_id, temperature = 0)\n",
    "    res.extend(outputs)\n",
    "\n",
    "res = [text['generated_text'] for text in res]\n",
    "\n",
    "# return a list of unique responses from the model\n",
    "print(set(res))\n",
    "\n",
    "# add results to the dataframe\n",
    "#motn['llama'] = [1 if '1' in text else 0 for text in res]\n",
    "# export results\n",
    "#motn.to_csv('./motn_test_llama3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49c71c5f-82c9-4ef4-8ad1-09d90234e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [num[0] for num in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85ba3e64-53a7-457f-8869-29ed0ec2903c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikeb\\AppData\\Local\\Temp\\ipykernel_24916\\1176831904.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  freedom['llama'] = [1 if '1' in text else 0 for text in res]\n"
     ]
    }
   ],
   "source": [
    "freedom['llama'] = [1 if '1' in text else 0 for text in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37186347-f47b-4797-b96b-e94e6abb9d35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8837671884459051"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(freedom['freedom_and_rights'], freedom['llama'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9e1309d-eb3e-46e2-a0a1-480642db3f2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8723670689479126"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(freedom['freedom_and_rights'], freedom['llama'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "22d9fa82-6ad5-44e6-9f41-657306ac0bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.833643930923096"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1(freedom['freedom_and_rights'], freedom['llama'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ae31ab2a-dc54-48ec-b96b-a8226c11af5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7448400510886073"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcc(freedom['freedom_and_rights'], freedom['llama'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
