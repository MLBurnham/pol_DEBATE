{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd1faa18-d38a-449e-9988-4e024932773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be206793-3944-4de2-a312-b77801a5311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset('mlburnham/Pol_NLI')\n",
    "test = ds['test'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bddc6c58-7629-44ca-857c-f39dba09fcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: train\n",
      "  Unique datasets: 21\n",
      "  Unique premises: 110155\n",
      "  Unique hypotheses: 769\n",
      "  Unique augmented hypotheses: 2531\n",
      "  Average premise length: 57.27 words\n",
      "  Entailment counts: {1: 95474, 0: 75815}\n",
      "\n",
      "Split: validation\n",
      "  Unique datasets: 21\n",
      "  Unique premises: 14231\n",
      "  Unique hypotheses: 648\n",
      "  Unique augmented hypotheses: 1628\n",
      "  Average premise length: 45.65 words\n",
      "  Entailment counts: {1: 8697, 0: 6339}\n",
      "\n",
      "Split: test\n",
      "  Unique datasets: 13\n",
      "  Unique premises: 13904\n",
      "  Unique hypotheses: 82\n",
      "  Unique augmented hypotheses: 297\n",
      "  Average premise length: 39.73 words\n",
      "  Entailment counts: {1: 9080, 0: 6286}\n",
      "\n",
      "Total unique datasets across all splits: 21\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "# Replace 'your_dataset_name' with the actual dataset name\n",
    "\n",
    "# Function to calculate descriptive statistics\n",
    "def describe_dataset(split):\n",
    "    df = ds[split].to_pandas()  # Convert the split to a pandas DataFrame\n",
    "\n",
    "    # Unique datasets\n",
    "    unique_datasets = df['dataset'].nunique()\n",
    "\n",
    "    # Unique premises, hypotheses, and augmented hypotheses\n",
    "    unique_premises = df['premise'].nunique()\n",
    "    unique_hypotheses = df['hypothesis'].nunique()\n",
    "    unique_augmented_hypotheses = df['augmented_hypothesis'].nunique()\n",
    "\n",
    "    # Average length of premises in terms of word count\n",
    "    avg_premise_word_count = df['premise'].apply(lambda x: len(x.split())).mean()\n",
    "\n",
    "    # Entailment counts\n",
    "    entailment_counts = df['entailment'].value_counts().to_dict()\n",
    "\n",
    "    return {\n",
    "        'unique_datasets': unique_datasets,\n",
    "        'unique_premises': unique_premises,\n",
    "        'unique_hypotheses': unique_hypotheses,\n",
    "        'unique_augmented_hypotheses': unique_augmented_hypotheses,\n",
    "        'avg_premise_word_count': avg_premise_word_count,\n",
    "        'entailment_counts': entailment_counts\n",
    "    }\n",
    "# Analyze each split\n",
    "splits = ['train', 'validation', 'test']\n",
    "results = {}\n",
    "\n",
    "for split in splits:\n",
    "    results[split] = describe_dataset(split)\n",
    "\n",
    "# Calculate total unique datasets across all splits\n",
    "all_datasets = pd.concat([ds[split].to_pandas() for split in splits])\n",
    "total_unique_datasets = all_datasets['dataset'].nunique()\n",
    "\n",
    "# Print results\n",
    "for split, stats in results.items():\n",
    "    print(f\"Split: {split}\")\n",
    "    print(f\"  Unique datasets: {stats['unique_datasets']}\")\n",
    "    print(f\"  Unique premises: {stats['unique_premises']}\")\n",
    "    print(f\"  Unique hypotheses: {stats['unique_hypotheses']}\")\n",
    "    print(f\"  Unique augmented hypotheses: {stats['unique_augmented_hypotheses']}\")\n",
    "    print(f\"  Average premise length: {stats['avg_premise_word_count']:.2f} words\")\n",
    "    print(f\"  Entailment counts: {stats['entailment_counts']}\")\n",
    "    print()\n",
    "\n",
    "print(f\"Total unique datasets across all splits: {total_unique_datasets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fcde1338-34be-4c37-97e7-aa8402332b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113251"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of not entail\n",
    "all_datasets['entailment'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c2f8ec43-f7e9-4d11-ab0a-4cede625b059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88440"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of entail\n",
    "all_datasets.shape[0] - all_datasets['entailment'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8be9642e-52e1-44b3-9143-57cda7419185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>entailment</th>\n",
       "      <th>dataset</th>\n",
       "      <th>augmented_hypothesis</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>event extraction</th>\n",
       "      <td>31234</td>\n",
       "      <td>31234</td>\n",
       "      <td>31234</td>\n",
       "      <td>31234</td>\n",
       "      <td>31234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hatespeech and toxicity</th>\n",
       "      <td>41871</td>\n",
       "      <td>41871</td>\n",
       "      <td>41871</td>\n",
       "      <td>41871</td>\n",
       "      <td>41871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stance detection</th>\n",
       "      <td>66581</td>\n",
       "      <td>66581</td>\n",
       "      <td>66581</td>\n",
       "      <td>66581</td>\n",
       "      <td>66581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic classification</th>\n",
       "      <td>62005</td>\n",
       "      <td>62005</td>\n",
       "      <td>62005</td>\n",
       "      <td>62005</td>\n",
       "      <td>62005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         premise  hypothesis  entailment  dataset  \\\n",
       "task                                                                \n",
       "event extraction           31234       31234       31234    31234   \n",
       "hatespeech and toxicity    41871       41871       41871    41871   \n",
       "stance detection           66581       66581       66581    66581   \n",
       "topic classification       62005       62005       62005    62005   \n",
       "\n",
       "                         augmented_hypothesis  \n",
       "task                                           \n",
       "event extraction                        31234  \n",
       "hatespeech and toxicity                 41871  \n",
       "stance detection                        66581  \n",
       "topic classification                    62005  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_datasets.groupby('task').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d7f6210-0ac3-448b-91a2-1bd1eba396ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          dataset  train  validation  test  \\\n",
      "0      mlburnham/global_warming_stance_entailment   3517          90     0   \n",
      "1         mlburnham/dem_rep_party_platform_topics  17287        2200  2377   \n",
      "2   mlburnham/argument_quality_ranking_entailment  14026        1389  1267   \n",
      "3            mlburnham/ibm_claimstance_entailment   2152         261   341   \n",
      "4      mlburnham/ibm_claimstance_topic_entailment   3180         506   407   \n",
      "5                  mlburnham/PoliStance_Affect_QT   2803          92   341   \n",
      "6                     mlburnham/PoliStance_Affect  23139        1427  3006   \n",
      "7                 mlburnham/hatespeech_entailment   2904          96     0   \n",
      "8         mlburnham/violent_hatespeech_entailment   5191        1396  1351   \n",
      "9    mlburnham/dehumanizing_hatespeech_entailment   5667         147   255   \n",
      "10       mlburnham/targeted_hatespeech_entailment  20002        1906  1396   \n",
      "11                  mlburnham/polarizing_rhetoric   1514          46     0   \n",
      "12                     mlburnham/political_or_not   4524         126     0   \n",
      "13                 mlburnham/anthropic_persuasion   1263         100     0   \n",
      "14              mlburnham/bill_summary_entailment  16172        1816  1723   \n",
      "15              mlburnham/polistance_issue_tweets  10993         336    38   \n",
      "16     mlburnham/supreme_court_summary_entailment  11353         334     0   \n",
      "17               mlburnham/acled_event_entailment  12612        1331  1818   \n",
      "18                mlburnham/scad_event_entailment   2537        1121  1046   \n",
      "19                mlburnham/adl_events_entailment   1628          43     0   \n",
      "20                 mlburnham/gtd_event_entailment   8825         273     0   \n",
      "\n",
      "    total_documents  \n",
      "0              3607  \n",
      "1             21864  \n",
      "2             16682  \n",
      "3              2754  \n",
      "4              4093  \n",
      "5              3236  \n",
      "6             27572  \n",
      "7              3000  \n",
      "8              7938  \n",
      "9              6069  \n",
      "10            23304  \n",
      "11             1560  \n",
      "12             4650  \n",
      "13             1363  \n",
      "14            19711  \n",
      "15            11367  \n",
      "16            11687  \n",
      "17            15761  \n",
      "18             4704  \n",
      "19             1671  \n",
      "20             9098  \n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to store the results\n",
    "dataset_info = {}\n",
    "\n",
    "# Iterate through each split\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    df = ds[split].to_pandas()  # Convert the split to a pandas DataFrame\n",
    "\n",
    "    # Get unique datasets in this split\n",
    "    unique_datasets = df['dataset'].unique()\n",
    "\n",
    "    # Update the dataset_info dictionary\n",
    "    for dataset_name in unique_datasets:\n",
    "        if dataset_name not in dataset_info:\n",
    "            dataset_info[dataset_name] = {'train': 0, 'validation': 0, 'test': 0}\n",
    "        dataset_info[dataset_name][split] = df[df['dataset'] == dataset_name].shape[0]\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "result_df = pd.DataFrame.from_dict(dataset_info, orient='index').reset_index()\n",
    "result_df.rename(columns={'index': 'dataset'}, inplace=True)\n",
    "\n",
    "# Add a column for the total number of documents\n",
    "result_df['total_documents'] = result_df[['train', 'validation', 'test']].sum(axis=1)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab3e636f-f173-4271-aa12-9ba108695383",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['dataset'] = result_df['dataset'].str.replace('mlburnham/', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "236ded27-d5e3-4919-a976-f9469557e0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15366"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['test'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "121927fd-15e8-4885-ac57-68a5ae17a012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "      <th>test</th>\n",
       "      <th>total_documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global Warming Stance</td>\n",
       "      <td>3517</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>3607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dem Rep Party Platform Topics</td>\n",
       "      <td>17287</td>\n",
       "      <td>2200</td>\n",
       "      <td>2377</td>\n",
       "      <td>21864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Argument Quality Ranking</td>\n",
       "      <td>14026</td>\n",
       "      <td>1389</td>\n",
       "      <td>1267</td>\n",
       "      <td>16682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ibm Claimstance</td>\n",
       "      <td>2152</td>\n",
       "      <td>261</td>\n",
       "      <td>341</td>\n",
       "      <td>2754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ibm Claimstance Topic</td>\n",
       "      <td>3180</td>\n",
       "      <td>506</td>\n",
       "      <td>407</td>\n",
       "      <td>4093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Polistance Affect Qt</td>\n",
       "      <td>2803</td>\n",
       "      <td>92</td>\n",
       "      <td>341</td>\n",
       "      <td>3236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Polistance Affect</td>\n",
       "      <td>23139</td>\n",
       "      <td>1427</td>\n",
       "      <td>3006</td>\n",
       "      <td>27572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hatespeech</td>\n",
       "      <td>2904</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Violent Hatespeech</td>\n",
       "      <td>5191</td>\n",
       "      <td>1396</td>\n",
       "      <td>1351</td>\n",
       "      <td>7938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dehumanizing Hatespeech</td>\n",
       "      <td>5667</td>\n",
       "      <td>147</td>\n",
       "      <td>255</td>\n",
       "      <td>6069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Targeted Hatespeech</td>\n",
       "      <td>20002</td>\n",
       "      <td>1906</td>\n",
       "      <td>1396</td>\n",
       "      <td>23304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Polarizing Rhetoric</td>\n",
       "      <td>1514</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Political Or Not</td>\n",
       "      <td>4524</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>4650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Anthropic Persuasion</td>\n",
       "      <td>1263</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bill Summary</td>\n",
       "      <td>16172</td>\n",
       "      <td>1816</td>\n",
       "      <td>1723</td>\n",
       "      <td>19711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Polistance Issue Tweets</td>\n",
       "      <td>10993</td>\n",
       "      <td>336</td>\n",
       "      <td>38</td>\n",
       "      <td>11367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Supreme Court Summary</td>\n",
       "      <td>11353</td>\n",
       "      <td>334</td>\n",
       "      <td>0</td>\n",
       "      <td>11687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Acled Event</td>\n",
       "      <td>12612</td>\n",
       "      <td>1331</td>\n",
       "      <td>1818</td>\n",
       "      <td>15761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Scad Event</td>\n",
       "      <td>2537</td>\n",
       "      <td>1121</td>\n",
       "      <td>1046</td>\n",
       "      <td>4704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Adl Events</td>\n",
       "      <td>1628</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>1671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Gtd Event</td>\n",
       "      <td>8825</td>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "      <td>9098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          dataset  train  validation  test  total_documents\n",
       "0           Global Warming Stance   3517          90     0             3607\n",
       "1   Dem Rep Party Platform Topics  17287        2200  2377            21864\n",
       "2        Argument Quality Ranking  14026        1389  1267            16682\n",
       "3                 Ibm Claimstance   2152         261   341             2754\n",
       "4           Ibm Claimstance Topic   3180         506   407             4093\n",
       "5            Polistance Affect Qt   2803          92   341             3236\n",
       "6               Polistance Affect  23139        1427  3006            27572\n",
       "7                      Hatespeech   2904          96     0             3000\n",
       "8              Violent Hatespeech   5191        1396  1351             7938\n",
       "9         Dehumanizing Hatespeech   5667         147   255             6069\n",
       "10            Targeted Hatespeech  20002        1906  1396            23304\n",
       "11            Polarizing Rhetoric   1514          46     0             1560\n",
       "12               Political Or Not   4524         126     0             4650\n",
       "13           Anthropic Persuasion   1263         100     0             1363\n",
       "14                   Bill Summary  16172        1816  1723            19711\n",
       "15        Polistance Issue Tweets  10993         336    38            11367\n",
       "16          Supreme Court Summary  11353         334     0            11687\n",
       "17                    Acled Event  12612        1331  1818            15761\n",
       "18                     Scad Event   2537        1121  1046             4704\n",
       "19                     Adl Events   1628          43     0             1671\n",
       "20                      Gtd Event   8825         273     0             9098"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['dataset'] = result_df['dataset'].str.replace('_entailment', '')\n",
    "result_df['dataset'] = result_df['dataset'].str.replace('_', ' ')\n",
    "result_df['dataset'] = result_df['dataset'].str.title()\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9cdfbbbc-3ba3-424d-9411-7b9c8a6eac63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3607\n",
      "21864\n",
      "16682\n",
      "2754\n",
      "4093\n",
      "3236\n",
      "27572\n",
      "3000\n",
      "7938\n",
      "6069\n",
      "23304\n",
      "1560\n",
      "4650\n",
      "1363\n",
      "19711\n",
      "11367\n",
      "11687\n",
      "15761\n",
      "4704\n",
      "1671\n",
      "9098\n"
     ]
    }
   ],
   "source": [
    "for data in result_df['total_documents']:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35162598-3016-44f8-803a-3df2261965ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           hypothesis  count\n",
      "0                        This text is about politics.   4650\n",
      "1                           This text is hate speech.   3000\n",
      "2   This text is defending people for their place ...   2570\n",
      "3        This court case is about criminal procedure.   2046\n",
      "4                     This text is about grenade use.   1896\n",
      "5                Climate change is a serious concern.   1814\n",
      "6                    Climate change is not a concern.   1793\n",
      "7                          This text is about health.   1723\n",
      "8   The author of this text supports stricter immi...   1707\n",
      "9   The author of this text opposes stricter immig...   1697\n",
      "10      This text is about crime and law enforcement.   1610\n",
      "11  This text advocates for violence against peopl...   1582\n",
      "12        This text is attacking political outgroups.   1560\n",
      "13        This court case is about economic activity.   1558\n",
      "14    This text is defending people for their gender.   1513\n",
      "15  The author of this text opposes government spe...   1507\n",
      "16  The author of this text is neutral towards trump.   1475\n",
      "17             The author of this text opposes trump.   1475\n",
      "18            The author of this text supports trump.   1475\n",
      "19    This text is attacking people for their gender.   1471\n"
     ]
    }
   ],
   "source": [
    "# Combine all splits into a single DataFrame\n",
    "all_data = pd.concat([ds[split].to_pandas() for split in ['train', 'validation', 'test']])\n",
    "\n",
    "# Count the occurrences of each hypothesis\n",
    "hypothesis_counts = all_data['hypothesis'].value_counts().reset_index()\n",
    "hypothesis_counts.columns = ['hypothesis', 'count']\n",
    "\n",
    "# Sort by count in descending order\n",
    "hypothesis_counts = hypothesis_counts.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Display the top N most common hypotheses\n",
    "top_n = 20  # Change this to display more or fewer results\n",
    "print(hypothesis_counts.head(top_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9f27b23-81b6-4740-8003-d30d80c3adc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            hypothesis  count\n",
      "832  This text advocates for violence against seniors.      4\n",
      "833  The author of this text opposes abolishing con...      4\n",
      "834  The author of this text opposes disbanding ASEAN.      4\n",
      "837  The author of this text does not believe that ...      3\n",
      "838      This text is attacking the visually impaired.      3\n",
      "836         This text is dehumanizing the middle aged.      3\n",
      "835  The author of this text believes that states s...      3\n",
      "839  The author of this text supports passing the A...      2\n",
      "840  The author of this text opposes passing the Am...      2\n",
      "841  The author of this text does not believe that ...      2\n",
      "842               This text is dehumanizing buddhists.      2\n",
      "843  The author of this text believes that housewiv...      2\n",
      "844  This text advocates for violence against the v...      1\n",
      "845       This text is attacking the hearing impaired.      1\n",
      "846         The author of this text opposes the squad.      1\n",
      "847   This text is dehumanizing the visually impaired.      1\n",
      "848  The author of this text is neutral towards the...      1\n",
      "849        The author of this text supports the squad.      1\n",
      "850       This text is defending the hearing impaired.      1\n",
      "851  This text is dehumanizing the neurologically d...      1\n"
     ]
    }
   ],
   "source": [
    "print(hypothesis_counts.tail(top_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea632591-4dde-460f-9ed2-4c666f188e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This text advocates for violence against seniors.\n",
      "The author of this text opposes abolishing congressional earmarks.\n",
      "The author of this text opposes disbanding ASEAN.\n",
      "The author of this text does not believe that states should not subsidize the growing of tobacco.\n",
      "This text is attacking the visually impaired.\n",
      "This text is dehumanizing the middle aged.\n",
      "The author of this text believes that states should not subsidize the growing of tobacco.\n",
      "The author of this text supports passing the American Jobs Act.\n",
      "The author of this text opposes passing the American Jobs Act.\n",
      "The author of this text does not believe that housewives should be paid for their work.\n",
      "This text is dehumanizing buddhists.\n",
      "The author of this text believes that housewives should be paid for their work.\n",
      "This text advocates for violence against the visually impaired.\n",
      "This text is attacking the hearing impaired.\n",
      "The author of this text opposes the squad.\n",
      "This text is dehumanizing the visually impaired.\n",
      "The author of this text is neutral towards the squad.\n",
      "The author of this text supports the squad.\n",
      "This text is defending the hearing impaired.\n",
      "This text is dehumanizing the neurologically disables.\n"
     ]
    }
   ],
   "source": [
    "for hypothesis in hypothesis_counts.tail(top_n)['hypothesis']:\n",
    "    print(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "460ba1c9-ae32-4d15-84ae-3eec69e1aee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236.72652582159625"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis_counts['count'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
