{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4462134d-3722-49d6-b95d-10f7919508f7",
   "metadata": {},
   "source": [
    "- implement with all 4 models\n",
    "- label all of covid data\n",
    "- implement generic benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78796f7a-dfd1-4da1-8be4-1930eee45b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mb7336/miniforge3/envs/sandbox/lib/python3.11/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/Users/mb7336/miniforge3/envs/sandbox/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <EB3FF92A-5EB1-3EE8-AF8B-5923C1265422> /Users/mb7336/miniforge3/envs/sandbox/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/Users/mb7336/miniforge3/envs/sandbox/lib/python3.11/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/mb7336/miniforge3/envs/sandbox/lib/python3.11/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/mb7336/miniforge3/envs/sandbox/lib/python3.11/lib-dynload/../../libjpeg.9.dylib' (no such file), '/Users/mb7336/miniforge3/envs/sandbox/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score, f1_score, balanced_accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"WANDB_PROJECT\"] = \"offline\"\n",
    "import accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6625680a-31a1-40c7-8852-f5f25d187ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "modname = 'mlburnham/Political_DEBATE_ModernBERT_base_v1.0'\n",
    "\n",
    "# Define label mapping\n",
    "id2label = {0: \"entailment\", 1: \"not_entailment\"}\n",
    "label2id = {'entailment':0, 'not_entialment':1}\n",
    "\n",
    "def tokenize_function(docs):\n",
    "    return tokenizer(docs['premise'], docs['hypothesis'], padding = False, truncation = False)\n",
    "\n",
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(modname, num_labels = 2, ignore_mismatched_sizes=True)\n",
    "\n",
    "def compute_metrics_standard(eval_pred, label_text_alphabetical=list(id2label.values())):\n",
    "    labels = eval_pred.label_ids\n",
    "    pred_logits = eval_pred.predictions\n",
    "    preds_max = np.argmax(pred_logits, axis=1)\n",
    "\n",
    "    # metrics\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(labels, preds_max, average='macro') \n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(labels, preds_max, average='micro')\n",
    "    acc_balanced = balanced_accuracy_score(labels, preds_max)\n",
    "    acc_not_balanced = accuracy_score(labels, preds_max)\n",
    "    mcc = matthews_corrcoef(labels, preds_max)\n",
    "\n",
    "    metrics = {'MCC': mcc,\n",
    "            'f1_macro': f1_macro,\n",
    "            'f1_micro': f1_micro,\n",
    "            'accuracy_balanced': acc_balanced,\n",
    "            'accuracy': acc_not_balanced,\n",
    "            'precision_macro': precision_macro,\n",
    "            'recall_macro': recall_macro,\n",
    "            'precision_micro': precision_micro,\n",
    "            'recall_micro': recall_micro,\n",
    "            }\n",
    "    print(\"Aggregate metrics: \", {key: metrics[key] for key in metrics if key not in [\"label_gold_raw\", \"label_predicted_raw\"]} )\n",
    "    print(\"Detailed metrics: \", classification_report(\n",
    "        labels, preds_max, labels=np.sort(pd.factorize(label_text_alphabetical, sort=True)[0]),\n",
    "        target_names=label_text_alphabetical, sample_weight=None,\n",
    "        digits=2, output_dict=True, zero_division='warn'),\n",
    "    \"\\n\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def metrics(df, preds, group_by=None):\n",
    "    true_col = 'entailment'\n",
    "    \n",
    "    def get_metrics(y_true, y_pred):\n",
    "        return {\n",
    "            'MCC': matthews_corrcoef(y_true, y_pred),\n",
    "            'Accuracy': accuracy_score(y_true, y_pred),\n",
    "            'F1': f1_score(y_true, y_pred, average='weighted')\n",
    "        }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    if group_by not in ['dataset', 'task']:\n",
    "        for col in preds:\n",
    "            metrics = get_metrics(df[true_col], df[col])\n",
    "            metrics['Column'] = col\n",
    "            results.append(metrics)\n",
    "    else:\n",
    "        for col in preds:\n",
    "            for group_name, group in df.groupby(group_by):\n",
    "                metrics = get_metrics(group[true_col], group[col])\n",
    "                metrics['Column'] = col\n",
    "                metrics[group_by.capitalize()] = group_name\n",
    "                results.append(metrics)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    if group_by in ['dataset', 'task']:\n",
    "        return results_df.set_index(['Column', group_by.capitalize()])\n",
    "    else:\n",
    "        return results_df.set_index('Column')\n",
    "        \n",
    "tokenizer = AutoTokenizer.from_pretrained(modname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d134d3d1-7adf-426c-94ca-83d604c62e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "polnli = pd.read_csv('../data/polnli_test_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e51bda42-c56d-417a-8baa-e9d54cb637e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97075fbbca604411ac1176e01eb83ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/171289 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2da40c1e2a4d459bfb2ac9b0eebd59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15036 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8fe3ef6e26f4035b9c7296b5ae1b23e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15366 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "polnli = load_dataset('mlburnham/Pol_NLI')\n",
    "\n",
    "nlitok = polnli.map(tokenize_function, batched = True)\n",
    "# Rename 'entailment' column to 'label'\n",
    "nlitok = nlitok.rename_columns({'entailment':'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eac5563d-3663-42e3-9b64-65511baffc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1q/xggcl4hn6mx_q8dfxbx_whpr0000gq/T/ipykernel_93935/1818552446.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['entailment'].replace({0:1, 1:0}, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/covid_tweets_labeled.csv')\n",
    "df = df[['text', 'non_comp']]\n",
    "df['hypothesis'] = 'The author of this tweet does not believe COVID is dangerous.'\n",
    "df.rename({'text':'premise', 'non_comp':'entailment'}, axis = 1, inplace = True)\n",
    "df['entailment'].replace({0:1, 1:0}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f7046dd-10d0-4802-957f-fda9baaf1f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c5619025f1141f3a97c08c4552c3285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e081a8842401480daaf98615545e8895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1962 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = df.sample(25, random_state = seed)\n",
    "# Create validation set with remaining instances\n",
    "val = df[~df.index.isin(train.index)]\n",
    "\n",
    "# Create a DatasetDict with train and validation splits\n",
    "ds = DatasetDict({'train': Dataset.from_pandas(train, preserve_index=False), 'validation':Dataset.from_pandas(val, preserve_index=False)})\n",
    "# Tokenize the dataset\n",
    "dstok = ds.map(tokenize_function, batched = True)\n",
    "# Rename 'entailment' column to 'label'\n",
    "dstok = dstok.rename_columns({'entailment':'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2931f82a-a568-4685-90ce-750b7ca43daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1q/xggcl4hn6mx_q8dfxbx_whpr0000gq/T/ipykernel_93935/2953300203.py:23: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(output_dir='../few_shot/',\n",
    "    logging_dir='../few_shot/',\n",
    "    lr_scheduler_type= \"linear\",\n",
    "    group_by_length=False,\n",
    "    learning_rate = 5e-5,#9e-6, # base seems to benefit from higher learning rate. Unsure about large.\n",
    "    per_device_train_batch_size = 2,\n",
    "    per_device_eval_batch_size = 16,\n",
    "    gradient_accumulation_steps = 1, \n",
    "    num_train_epochs=5,\n",
    "    warmup_ratio=0.05,  \n",
    "    weight_decay=0.01, \n",
    "    fp16=False,   \n",
    "    fp16_full_eval=False,\n",
    "    eval_strategy=\"no\",\n",
    "    seed=seed,\n",
    "    save_strategy=\"no\",\n",
    "    dataloader_num_workers = 1,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(modname)\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model_init = model_init,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=dstok['train'],\n",
    "    eval_dataset=dstok['validation'],\n",
    "    compute_metrics=lambda x: compute_metrics_standard(x, label_text_alphabetical=list(id2label.values()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d2eb25db-35f0-4f43-b8b0-8a481b7ae6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [65/65 00:41, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=65, training_loss=0.521470935528095, metrics={'train_runtime': 43.2781, 'train_samples_per_second': 2.888, 'train_steps_per_second': 1.502, 'total_flos': 8554885454472.0, 'train_loss': 0.521470935528095, 'epoch': 5.0})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "73db244f-cfb1-41b7-8f79-ffdca445b029",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate metrics:  {'MCC': 0.27983788896423273, 'f1_macro': 0.6397498026070545, 'f1_micro': 0.7130479102956168, 'accuracy_balanced': 0.6421175067104086, 'accuracy': 0.7130479102956168, 'precision_macro': 0.6377543940795559, 'recall_macro': 0.6421175067104086, 'precision_micro': 0.7130479102956168, 'recall_micro': 0.7130479102956168}\n",
      "Detailed metrics:  {'entailment': {'precision': 0.46557971014492755, 'recall': 0.4895238095238095, 'f1-score': 0.4772516248839369, 'support': 525.0}, 'not_entailment': {'precision': 0.8099290780141843, 'recall': 0.7947112038970077, 'f1-score': 0.8022479803301721, 'support': 1437.0}, 'accuracy': 0.7130479102956168, 'macro avg': {'precision': 0.6377543940795559, 'recall': 0.6421175067104086, 'f1-score': 0.6397498026070545, 'support': 1962.0}, 'weighted avg': {'precision': 0.7177866630644597, 'recall': 0.7130479102956168, 'f1-score': 0.7152841237505221, 'support': 1962.0}} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1q/xggcl4hn6mx_q8dfxbx_whpr0000gq/T/ipykernel_93935/502960004.py:38: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  labels, preds_max, labels=np.sort(pd.factorize(label_text_alphabetical, sort=True)[0]),\n"
     ]
    }
   ],
   "source": [
    "res = trainer.predict(dstok['validation'])\n",
    "preds = np.argmax(res.predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2aa0863e-9f1d-44eb-98ff-72ae33b605dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate metrics:  {'MCC': 0.27983788896423273, 'f1_macro': 0.6397498026070545, 'f1_micro': 0.7130479102956168, 'accuracy_balanced': 0.6421175067104086, 'accuracy': 0.7130479102956168, 'precision_macro': 0.6377543940795559, 'recall_macro': 0.6421175067104086, 'precision_micro': 0.7130479102956168, 'recall_micro': 0.7130479102956168}\n",
      "Detailed metrics:  {'entailment': {'precision': 0.46557971014492755, 'recall': 0.4895238095238095, 'f1-score': 0.4772516248839369, 'support': 525.0}, 'not_entailment': {'precision': 0.8099290780141843, 'recall': 0.7947112038970077, 'f1-score': 0.8022479803301721, 'support': 1437.0}, 'accuracy': 0.7130479102956168, 'macro avg': {'precision': 0.6377543940795559, 'recall': 0.6421175067104086, 'f1-score': 0.6397498026070545, 'support': 1962.0}, 'weighted avg': {'precision': 0.7177866630644597, 'recall': 0.7130479102956168, 'f1-score': 0.7152841237505221, 'support': 1962.0}} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1q/xggcl4hn6mx_q8dfxbx_whpr0000gq/T/ipykernel_93935/502960004.py:38: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  labels, preds_max, labels=np.sort(pd.factorize(label_text_alphabetical, sort=True)[0]),\n"
     ]
    }
   ],
   "source": [
    "res = trainer.predict(dstok['validation'])\n",
    "preds = np.argmax(res.predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8116d3b2-ad15-46d6-8c8b-b2a223721cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1q/xggcl4hn6mx_q8dfxbx_whpr0000gq/T/ipykernel_92972/2759960519.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val['preds'] = preds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MCC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>0.623038</td>\n",
       "      <td>0.858308</td>\n",
       "      <td>0.854046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MCC  Accuracy        F1\n",
       "Column                              \n",
       "preds   0.623038  0.858308  0.854046"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val['preds'] = preds\n",
    "metrics(val, ['preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9dff437-2991-4041-98fb-70ef576c0531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate metrics:  {'MCC': 0.8969777235203986, 'f1_macro': 0.9483258928158771, 'f1_micro': 0.9502798386047117, 'accuracy_balanced': 0.9462056265163759, 'accuracy': 0.9502798386047117, 'precision_macro': 0.9507837803241533, 'recall_macro': 0.9462056265163759, 'precision_micro': 0.9502798386047117, 'recall_micro': 0.9502798386047117}\n",
      "Detailed metrics:  {'entailment': {'precision': 0.9532173342087984, 'recall': 0.9237989182309895, 'f1-score': 0.9382775892712877, 'support': 6286.0}, 'not_entailment': {'precision': 0.9483502264395083, 'recall': 0.9686123348017621, 'f1-score': 0.9583741963604664, 'support': 9080.0}, 'accuracy': 0.9502798386047117, 'macro avg': {'precision': 0.9507837803241533, 'recall': 0.9462056265163759, 'f1-score': 0.9483258928158771, 'support': 15366.0}, 'weighted avg': {'precision': 0.9503412871864664, 'recall': 0.9502798386047117, 'f1-score': 0.9501529759932545, 'support': 15366.0}} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1q/xggcl4hn6mx_q8dfxbx_whpr0000gq/T/ipykernel_93935/705763776.py:38: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  labels, preds_max, labels=np.sort(pd.factorize(label_text_alphabetical, sort=True)[0]),\n"
     ]
    }
   ],
   "source": [
    "nlires = trainer.predict(nlitok['test'])\n",
    "nlipreds = np.argmax(nlires.predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae62212e-9b11-4efc-93ae-094f48d16ee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MCC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fs</th>\n",
       "      <td>0.896976</td>\n",
       "      <td>0.95028</td>\n",
       "      <td>0.950154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MCC  Accuracy        F1\n",
       "Column                              \n",
       "fs      0.896976   0.95028  0.950154"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nli = polnli['test'].to_pandas()\n",
    "nli['fs'] = nlipreds\n",
    "\n",
    "metrics(nli, ['fs'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
