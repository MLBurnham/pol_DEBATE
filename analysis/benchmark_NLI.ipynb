{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee35429f-a5ff-42a3-ba53-46f5cc4aa1d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score, f1_score\n",
    "from datasets import load_dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "290bec66-fb87-4a1d-bd12-4863c5cf47de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since mlburnham/PolNLI couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /home/mike/.cache/huggingface/datasets/mlburnham___pol_nli/default/0.0.0/062724c0a0e601ffc5fba98a5546cc2237a766fa (last modified on Tue Jan  7 00:25:02 2025).\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "ds = load_dataset('mlburnham/PolNLI')\n",
    "train = ds['train'].to_pandas()\n",
    "test = pd.read_csv('./data/polnli_test_results.csv')\n",
    "\n",
    "# convert to dictionary of document pairs to pass through the pipeline\n",
    "docs_dict = [{'text':test.loc[i, 'premise'], 'text_pair':test.loc[i, 'augmented_hypothesis']} for i in test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77960290-3439-4864-99bc-931da719e276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(df, preds, group_by=None):\n",
    "    \"\"\"\n",
    "    Calculate metrics grouped by model, dataset, task.\n",
    "    \"\"\"\n",
    "    true_col = 'entailment'\n",
    "    \n",
    "    def get_metrics(y_true, y_pred):\n",
    "        return {\n",
    "            'MCC': matthews_corrcoef(y_true, y_pred),\n",
    "            'Accuracy': accuracy_score(y_true, y_pred),\n",
    "            'F1': f1_score(y_true, y_pred, average='weighted')\n",
    "        }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    if group_by not in ['dataset', 'task']:\n",
    "        for col in preds:\n",
    "            metrics = get_metrics(df[true_col], df[col])\n",
    "            metrics['Column'] = col\n",
    "            results.append(metrics)\n",
    "    else:\n",
    "        for col in preds:\n",
    "            for group_name, group in df.groupby(group_by):\n",
    "                metrics = get_metrics(group[true_col], group[col])\n",
    "                metrics['Column'] = col\n",
    "                metrics[group_by.capitalize()] = group_name\n",
    "                results.append(metrics)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    if group_by in ['dataset', 'task']:\n",
    "        return results_df.set_index(['Column', group_by.capitalize()])\n",
    "    else:\n",
    "        return results_df.set_index('Column')\n",
    "\n",
    "def label_docs(model, docs_dict, batch_size = 32, device = 'cuda'):\n",
    "    \"\"\"\n",
    "    Passes documents through the pipeline. Returns a list of entail, not_entail labels\n",
    "    \"\"\"\n",
    "    pipe = pipeline(task = 'text-classification', model = model, \n",
    "                    batch_size = batch_size, device = device, \n",
    "                    max_length = 512, truncation = True, \n",
    "                    torch_dtype = torch.bfloat16)\n",
    "    res = pipe(docs_dict)\n",
    "    res = [result['label'] for result in res]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376cc915-6fde-492d-9117-a0042898f510",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ef0cb2f-5470-44bc-8675-219696a9368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models that will be tested\n",
    "models = [\"MoritzLaurer/deberta-v3-base-zeroshot-v2.0\", \n",
    "          \"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\",\n",
    "          \"training_base/checkpoint-96354\",\n",
    "          \"mlburnham/Political_DEBATE_large_v1.0\",\n",
    "          \"training_ModernBase/checkpoint-96354\",\n",
    "          \"training_ModernLarge/checkpoint-74935\"]\n",
    "\n",
    "# column names that will hold results\n",
    "columns = ['base_nli',\n",
    "           'large_nli',\n",
    "           'base_debate',\n",
    "           'large_debate',\n",
    "           'base_modern',\n",
    "           'large_modern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b77a8620-19e0-491f-becb-f4da0c5c0ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "<timed exec>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoritzLaurer/deberta-v3-base-zeroshot-v2.0 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoritzLaurer/deberta-v3-large-zeroshot-v2.0 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_base/checkpoint-96354 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "<timed exec>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlburnham/Political_DEBATE_large_v1.0 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Device set to use cuda\n",
      "<timed exec>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_ModernBase/checkpoint-96354 complete.\n",
      "training_ModernLarge/checkpoint-74935 complete.\n",
      "CPU times: user 3min 10s, sys: 5.22 s, total: 3min 16s\n",
      "Wall time: 3min 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# for each model, classify documents and return labels to the test dataframe\n",
    "for modname, col in zip(models, columns):\n",
    "    res = label_docs(modname, docs_dict)\n",
    "    test[col] = res\n",
    "    test[col] = test[col].replace({'entailment': 0, 'not_entailment': 1})\n",
    "    print(modname + ' complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f1c1e7-5104-4ba1-8f08-9cb84f7469c5",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53b1752d-9165-4b82-a90a-98950a7e3d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MCC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base_nli</th>\n",
       "      <td>0.657027</td>\n",
       "      <td>0.834375</td>\n",
       "      <td>0.830335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>large_nli</th>\n",
       "      <td>0.718800</td>\n",
       "      <td>0.863074</td>\n",
       "      <td>0.859911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_debate</th>\n",
       "      <td>0.892088</td>\n",
       "      <td>0.947872</td>\n",
       "      <td>0.947670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>large_debate</th>\n",
       "      <td>0.915911</td>\n",
       "      <td>0.959326</td>\n",
       "      <td>0.959180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_modern</th>\n",
       "      <td>0.877708</td>\n",
       "      <td>0.940843</td>\n",
       "      <td>0.940859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>large_modern</th>\n",
       "      <td>0.913069</td>\n",
       "      <td>0.958024</td>\n",
       "      <td>0.957987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   MCC  Accuracy        F1\n",
       "Column                                    \n",
       "base_nli      0.657027  0.834375  0.830335\n",
       "large_nli     0.718800  0.863074  0.859911\n",
       "base_debate   0.892088  0.947872  0.947670\n",
       "large_debate  0.915911  0.959326  0.959180\n",
       "base_modern   0.877708  0.940843  0.940859\n",
       "large_modern  0.913069  0.958024  0.957987"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics(test, preds = columns, group_by = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "364e00fe-6928-4937-a304-419e71d4531b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MCC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column</th>\n",
       "      <th>Task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">base_nli</th>\n",
       "      <th>event extraction</th>\n",
       "      <td>0.538591</td>\n",
       "      <td>0.753841</td>\n",
       "      <td>0.753169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hatespeech and toxicity</th>\n",
       "      <td>0.550569</td>\n",
       "      <td>0.858095</td>\n",
       "      <td>0.845361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stance detection</th>\n",
       "      <td>0.530711</td>\n",
       "      <td>0.775285</td>\n",
       "      <td>0.770202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic classification</th>\n",
       "      <td>0.871001</td>\n",
       "      <td>0.935212</td>\n",
       "      <td>0.934550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">large_nli</th>\n",
       "      <th>event extraction</th>\n",
       "      <td>0.723042</td>\n",
       "      <td>0.852304</td>\n",
       "      <td>0.852599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hatespeech and toxicity</th>\n",
       "      <td>0.553551</td>\n",
       "      <td>0.854430</td>\n",
       "      <td>0.848143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stance detection</th>\n",
       "      <td>0.585007</td>\n",
       "      <td>0.797717</td>\n",
       "      <td>0.789429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic classification</th>\n",
       "      <td>0.896400</td>\n",
       "      <td>0.948081</td>\n",
       "      <td>0.947663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">base_debate</th>\n",
       "      <th>event extraction</th>\n",
       "      <td>0.765923</td>\n",
       "      <td>0.878492</td>\n",
       "      <td>0.878934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hatespeech and toxicity</th>\n",
       "      <td>0.856644</td>\n",
       "      <td>0.950700</td>\n",
       "      <td>0.950405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stance detection</th>\n",
       "      <td>0.938404</td>\n",
       "      <td>0.970158</td>\n",
       "      <td>0.970135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic classification</th>\n",
       "      <td>0.929391</td>\n",
       "      <td>0.965387</td>\n",
       "      <td>0.965351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">large_debate</th>\n",
       "      <th>event extraction</th>\n",
       "      <td>0.819049</td>\n",
       "      <td>0.909218</td>\n",
       "      <td>0.909492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hatespeech and toxicity</th>\n",
       "      <td>0.882548</td>\n",
       "      <td>0.959694</td>\n",
       "      <td>0.959374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stance detection</th>\n",
       "      <td>0.969009</td>\n",
       "      <td>0.984979</td>\n",
       "      <td>0.984972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic classification</th>\n",
       "      <td>0.924496</td>\n",
       "      <td>0.962503</td>\n",
       "      <td>0.962322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">base_modern</th>\n",
       "      <th>event extraction</th>\n",
       "      <td>0.798288</td>\n",
       "      <td>0.900838</td>\n",
       "      <td>0.900697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hatespeech and toxicity</th>\n",
       "      <td>0.833822</td>\n",
       "      <td>0.941372</td>\n",
       "      <td>0.941764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stance detection</th>\n",
       "      <td>0.890244</td>\n",
       "      <td>0.946725</td>\n",
       "      <td>0.946748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic classification</th>\n",
       "      <td>0.917187</td>\n",
       "      <td>0.959396</td>\n",
       "      <td>0.959332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">large_modern</th>\n",
       "      <th>event extraction</th>\n",
       "      <td>0.864006</td>\n",
       "      <td>0.932961</td>\n",
       "      <td>0.932989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hatespeech and toxicity</th>\n",
       "      <td>0.864167</td>\n",
       "      <td>0.952698</td>\n",
       "      <td>0.952748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stance detection</th>\n",
       "      <td>0.930965</td>\n",
       "      <td>0.966553</td>\n",
       "      <td>0.966532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic classification</th>\n",
       "      <td>0.934889</td>\n",
       "      <td>0.968050</td>\n",
       "      <td>0.967998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           MCC  Accuracy        F1\n",
       "Column       Task                                                 \n",
       "base_nli     event extraction         0.538591  0.753841  0.753169\n",
       "             hatespeech and toxicity  0.550569  0.858095  0.845361\n",
       "             stance detection         0.530711  0.775285  0.770202\n",
       "             topic classification     0.871001  0.935212  0.934550\n",
       "large_nli    event extraction         0.723042  0.852304  0.852599\n",
       "             hatespeech and toxicity  0.553551  0.854430  0.848143\n",
       "             stance detection         0.585007  0.797717  0.789429\n",
       "             topic classification     0.896400  0.948081  0.947663\n",
       "base_debate  event extraction         0.765923  0.878492  0.878934\n",
       "             hatespeech and toxicity  0.856644  0.950700  0.950405\n",
       "             stance detection         0.938404  0.970158  0.970135\n",
       "             topic classification     0.929391  0.965387  0.965351\n",
       "large_debate event extraction         0.819049  0.909218  0.909492\n",
       "             hatespeech and toxicity  0.882548  0.959694  0.959374\n",
       "             stance detection         0.969009  0.984979  0.984972\n",
       "             topic classification     0.924496  0.962503  0.962322\n",
       "base_modern  event extraction         0.798288  0.900838  0.900697\n",
       "             hatespeech and toxicity  0.833822  0.941372  0.941764\n",
       "             stance detection         0.890244  0.946725  0.946748\n",
       "             topic classification     0.917187  0.959396  0.959332\n",
       "large_modern event extraction         0.864006  0.932961  0.932989\n",
       "             hatespeech and toxicity  0.864167  0.952698  0.952748\n",
       "             stance detection         0.930965  0.966553  0.966532\n",
       "             topic classification     0.934889  0.968050  0.967998"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics(test, preds = columns, group_by = 'task')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4802bbbb-a809-4819-8308-73e60a92eb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MCC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column</th>\n",
       "      <th>Dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">base_nli</th>\n",
       "      <th>mlburnham/PoliStance_Affect</th>\n",
       "      <td>0.496475</td>\n",
       "      <td>0.763473</td>\n",
       "      <td>0.759936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlburnham/PoliStance_Affect_QT</th>\n",
       "      <td>0.043096</td>\n",
       "      <td>0.563050</td>\n",
       "      <td>0.555894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlburnham/acled_event_entailment</th>\n",
       "      <td>0.503271</td>\n",
       "      <td>0.707371</td>\n",
       "      <td>0.689879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlburnham/argument_quality_ranking_entailment</th>\n",
       "      <td>0.760144</td>\n",
       "      <td>0.872139</td>\n",
       "      <td>0.869139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlburnham/bill_summary_entailment</th>\n",
       "      <td>0.877433</td>\n",
       "      <td>0.936158</td>\n",
       "      <td>0.936137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">large_modern</th>\n",
       "      <th>mlburnham/ibm_claimstance_topic_entailment</th>\n",
       "      <td>0.966931</td>\n",
       "      <td>0.985258</td>\n",
       "      <td>0.985285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlburnham/polistance_issue_tweets</th>\n",
       "      <td>0.697486</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.977890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlburnham/scad_event_entailment</th>\n",
       "      <td>0.784786</td>\n",
       "      <td>0.896750</td>\n",
       "      <td>0.897376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlburnham/targeted_hatespeech_entailment</th>\n",
       "      <td>0.697502</td>\n",
       "      <td>0.962751</td>\n",
       "      <td>0.962563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlburnham/violent_hatespeech_entailment</th>\n",
       "      <td>0.883781</td>\n",
       "      <td>0.946706</td>\n",
       "      <td>0.946681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 MCC  \\\n",
       "Column       Dataset                                                   \n",
       "base_nli     mlburnham/PoliStance_Affect                    0.496475   \n",
       "             mlburnham/PoliStance_Affect_QT                 0.043096   \n",
       "             mlburnham/acled_event_entailment               0.503271   \n",
       "             mlburnham/argument_quality_ranking_entailment  0.760144   \n",
       "             mlburnham/bill_summary_entailment              0.877433   \n",
       "...                                                              ...   \n",
       "large_modern mlburnham/ibm_claimstance_topic_entailment     0.966931   \n",
       "             mlburnham/polistance_issue_tweets              0.697486   \n",
       "             mlburnham/scad_event_entailment                0.784786   \n",
       "             mlburnham/targeted_hatespeech_entailment       0.697502   \n",
       "             mlburnham/violent_hatespeech_entailment        0.883781   \n",
       "\n",
       "                                                            Accuracy        F1  \n",
       "Column       Dataset                                                            \n",
       "base_nli     mlburnham/PoliStance_Affect                    0.763473  0.759936  \n",
       "             mlburnham/PoliStance_Affect_QT                 0.563050  0.555894  \n",
       "             mlburnham/acled_event_entailment               0.707371  0.689879  \n",
       "             mlburnham/argument_quality_ranking_entailment  0.872139  0.869139  \n",
       "             mlburnham/bill_summary_entailment              0.936158  0.936137  \n",
       "...                                                              ...       ...  \n",
       "large_modern mlburnham/ibm_claimstance_topic_entailment     0.985258  0.985285  \n",
       "             mlburnham/polistance_issue_tweets              0.973684  0.977890  \n",
       "             mlburnham/scad_event_entailment                0.896750  0.897376  \n",
       "             mlburnham/targeted_hatespeech_entailment       0.962751  0.962563  \n",
       "             mlburnham/violent_hatespeech_entailment        0.946706  0.946681  \n",
       "\n",
       "[78 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics(test, preds = columns, group_by = 'dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e006f6d-04c6-4a35-94b9-23af82d83b1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.to_csv('data/polnli_test_results.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
