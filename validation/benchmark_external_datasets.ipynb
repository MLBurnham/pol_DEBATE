{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cfa482f-2ce5-4cb7-a1f5-c2da1aca32ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27fac9a3-0c1d-4638-8660-00d6c958fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(df, preds, group_by=None):\n",
    "    \"\"\"\n",
    "    Calculate MCC, Accuracy, F1 for predictions.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing true and predicted labels.\n",
    "        preds (list): List of column names containing model predictions.\n",
    "        group_by (str, optional): Column name to group by ('dataset' or 'task'). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with calculated metrics, optionally grouped by `group_by`.\n",
    "    \"\"\"\n",
    "    true_col = 'entailment'\n",
    "    \n",
    "    def get_metrics(y_true, y_pred):\n",
    "        return {\n",
    "            'MCC': matthews_corrcoef(y_true, y_pred),\n",
    "            'Accuracy': accuracy_score(y_true, y_pred),\n",
    "            'F1': f1_score(y_true, y_pred, average='macro')\n",
    "        }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    if group_by not in ['dataset', 'task']:\n",
    "        for col in preds:\n",
    "            metrics = get_metrics(df[true_col], df[col])\n",
    "            metrics['Column'] = col\n",
    "            results.append(metrics)\n",
    "    else:\n",
    "        for col in preds:\n",
    "            for group_name, group in df.groupby(group_by):\n",
    "                metrics = get_metrics(group[true_col], group[col])\n",
    "                metrics['Column'] = col\n",
    "                metrics[group_by.capitalize()] = group_name\n",
    "                results.append(metrics)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    if group_by in ['dataset', 'task']:\n",
    "        return results_df.set_index(['Column', group_by.capitalize()])\n",
    "    else:\n",
    "        return results_df.set_index('Column')\n",
    "\n",
    "def bootstrapped_errors(y_true, y_pred, n_bootstrap=1000):\n",
    "    \"\"\"\n",
    "    Calculate bootstrapped standard errors for MCC, Accuracy, and F1.\n",
    "\n",
    "    Args:\n",
    "        y_true (array-like): True labels.\n",
    "        y_pred (array-like): Predicted labels.\n",
    "        n_bootstrap (int, optional): Number of bootstrap samples. Defaults to 1000.\n",
    "\n",
    "    Returns:\n",
    "        dict: Standard errors for MCC, Accuracy, and F1.\n",
    "    \"\"\"\n",
    "    mcc_scores = []\n",
    "    accuracy_scores = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for _ in range(n_bootstrap):\n",
    "        # Resample with replacement\n",
    "        y_true_resampled, y_pred_resampled = resample(y_true, y_pred)\n",
    "        \n",
    "        # Calculate metrics for the resampled data\n",
    "        mcc_scores.append(matthews_corrcoef(y_true_resampled, y_pred_resampled))\n",
    "        accuracy_scores.append(accuracy_score(y_true_resampled, y_pred_resampled))\n",
    "        f1_scores.append(f1_score(y_true_resampled, y_pred_resampled, average='weighted'))\n",
    "    \n",
    "    # Calculate standard errors\n",
    "    return {\n",
    "        'MCC_SE': np.std(mcc_scores),\n",
    "        'Accuracy_SE': np.std(accuracy_scores),\n",
    "        'F1_SE': np.std(f1_scores)\n",
    "    }\n",
    "\n",
    "def metrics_with_errors(df, preds, n_bootstrap=1000, group_by=None):\n",
    "    \"\"\"\n",
    "    Calculate metrics and bootstrapped standard errors for predictions, optionally grouped.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing true and predicted labels.\n",
    "        preds (list): List of column names containing model predictions.\n",
    "        n_bootstrap (int, optional): Number of bootstrap samples. Defaults to 1000.\n",
    "        group_by (str, optional): Column name to group by ('dataset' or 'task'). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Combined DataFrame of metrics, standard errors, and confidence intervals.\n",
    "    \"\"\"\n",
    "    # Step 1: Calculate metrics for each model\n",
    "    metrics_df = metrics(df, preds, group_by=group_by)\n",
    "\n",
    "    # Step 2: Calculate bootstrapped errors for each model or group\n",
    "    errors = []\n",
    "    if group_by not in ['dataset', 'task']:\n",
    "        for col in preds:\n",
    "            y_true = df['entailment']\n",
    "            y_pred = df[col]\n",
    "            errors_dict = bootstrapped_errors(y_true, y_pred, n_bootstrap=n_bootstrap)\n",
    "            errors_dict['Column'] = col\n",
    "            errors.append(errors_dict)\n",
    "    else:\n",
    "        for col in preds:\n",
    "            for group_name, group in df.groupby(group_by):\n",
    "                y_true = group['entailment']\n",
    "                y_pred = group[col]\n",
    "                errors_dict = bootstrapped_errors(y_true, y_pred, n_bootstrap=n_bootstrap)\n",
    "                errors_dict['Column'] = col\n",
    "                errors_dict[group_by.capitalize()] = group_name\n",
    "                errors.append(errors_dict)\n",
    "\n",
    "    errors_df = pd.DataFrame(errors)\n",
    "\n",
    "    if group_by in ['dataset', 'task']:\n",
    "        errors_df = errors_df.set_index(['Column', group_by.capitalize()])\n",
    "    else:\n",
    "        errors_df = errors_df.set_index('Column')\n",
    "\n",
    "    # Step 3: Merge metrics and errors DataFrames\n",
    "    combined_df = metrics_df.merge(errors_df, left_index=True, right_index=True)\n",
    "\n",
    "    # Step 4: Calculate confidence intervals (upper and lower bounds)\n",
    "    combined_df['MCC_Lower'] = combined_df['MCC'] - combined_df['MCC_SE']\n",
    "    combined_df['MCC_Upper'] = combined_df['MCC'] + combined_df['MCC_SE']\n",
    "\n",
    "    combined_df['Accuracy_Lower'] = combined_df['Accuracy'] - combined_df['Accuracy_SE']\n",
    "    combined_df['Accuracy_Upper'] = combined_df['Accuracy'] + combined_df['Accuracy_SE']\n",
    "\n",
    "    combined_df['F1_Lower'] = combined_df['F1'] - combined_df['F1_SE']\n",
    "    combined_df['F1_Upper'] = combined_df['F1'] + combined_df['F1_SE']\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "def label_docs(model, docs_dict, batch_size = 8, device = 'cuda'):\n",
    "    \"\"\"\n",
    "    Passes documents through the pipeline. Returns a list of entail, not_entail labels\n",
    "    \"\"\"\n",
    "    pipe = pipeline(task = 'text-classification', model = model, \n",
    "                    batch_size = batch_size, device = device, \n",
    "                    max_length = 512, truncation = True, \n",
    "                    torch_dtype = torch.bfloat16)\n",
    "    res = pipe(docs_dict)\n",
    "    res = [result['label'] for result in res]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caffab69-841e-4def-828e-d99e8f64f490",
   "metadata": {},
   "source": [
    "# UKP Stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03d9e930-5b27-446e-ae42-2ed0c71a495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukp = pd.read_csv('../data/ukp_stance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af76bcca-49b4-4c27-86b8-86f75a08de8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_dict = [{'text':ukp.loc[i, 'text'], 'text_pair':ukp.loc[i, 'hypothesis']} for i in ukp.index]\n",
    "\n",
    "# models that will be tested\n",
    "models = [\"MoritzLaurer/deberta-v3-base-zeroshot-v2.0\", \n",
    "          \"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\",\n",
    "          \"mlburnham/Political_DEBATE_DeBERTa_base_v1.1\",\n",
    "          \"mlburnham/Political_DEBATE_DeBERTa_large_v1.1\",\n",
    "          \"mlburnham/Political_DEBATE_ModernBERT_base_v1.0\",\n",
    "          \"mlburnham/Political_DEBATE_ModernBERT_large_v1.0\"]\n",
    "\n",
    "# column names that will hold results\n",
    "columns = ['base_nli',\n",
    "           'large_nli',\n",
    "           'base_debate',\n",
    "           'large_debate',\n",
    "           'base_modern',\n",
    "           'large_modern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a66e2613-faf8-483e-8e2e-072daee292da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "<timed exec>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoritzLaurer/deberta-v3-base-zeroshot-v2.0 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "<timed exec>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoritzLaurer/deberta-v3-large-zeroshot-v2.0 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "<timed exec>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlburnham/Political_DEBATE_DeBERTa_base_v1.1 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "<timed exec>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlburnham/Political_DEBATE_DeBERTa_large_v1.1 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Device set to use cuda\n",
      "<timed exec>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlburnham/Political_DEBATE_ModernBERT_base_v1.0 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlburnham/Political_DEBATE_ModernBERT_large_v1.0 complete.\n",
      "CPU times: user 52.8 s, sys: 10.3 s, total: 1min 3s\n",
      "Wall time: 55.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# for each model, classify documents and return labels to the test dataframe\n",
    "for modname, col in zip(models, columns):\n",
    "    res = label_docs(modname, docs_dict, batch_size = 8, device = 'cuda')\n",
    "    ukp[col] = res\n",
    "    ukp[col] = ukp[col].replace({'entailment': 0, 'not_entailment': 1})\n",
    "    print(modname + ' complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2516f8bc-962d-4103-b944-d500c2568c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.66 s, sys: 0 ns, total: 9.66 s\n",
      "Wall time: 7.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MCC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>MCC_SE</th>\n",
       "      <th>Accuracy_SE</th>\n",
       "      <th>F1_SE</th>\n",
       "      <th>MCC_Lower</th>\n",
       "      <th>MCC_Upper</th>\n",
       "      <th>Accuracy_Lower</th>\n",
       "      <th>Accuracy_Upper</th>\n",
       "      <th>F1_Lower</th>\n",
       "      <th>F1_Upper</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base_nli</th>\n",
       "      <td>0.598784</td>\n",
       "      <td>0.828659</td>\n",
       "      <td>0.798812</td>\n",
       "      <td>0.012397</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.005465</td>\n",
       "      <td>0.586387</td>\n",
       "      <td>0.611181</td>\n",
       "      <td>0.823286</td>\n",
       "      <td>0.834032</td>\n",
       "      <td>0.793347</td>\n",
       "      <td>0.804277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>large_nli</th>\n",
       "      <td>0.720828</td>\n",
       "      <td>0.880488</td>\n",
       "      <td>0.850004</td>\n",
       "      <td>0.010343</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>0.005080</td>\n",
       "      <td>0.710485</td>\n",
       "      <td>0.731171</td>\n",
       "      <td>0.875842</td>\n",
       "      <td>0.885133</td>\n",
       "      <td>0.844924</td>\n",
       "      <td>0.855083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_debate</th>\n",
       "      <td>0.771101</td>\n",
       "      <td>0.896951</td>\n",
       "      <td>0.884403</td>\n",
       "      <td>0.009471</td>\n",
       "      <td>0.004323</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>0.761630</td>\n",
       "      <td>0.780572</td>\n",
       "      <td>0.892628</td>\n",
       "      <td>0.901274</td>\n",
       "      <td>0.880166</td>\n",
       "      <td>0.888640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>large_debate</th>\n",
       "      <td>0.854828</td>\n",
       "      <td>0.934146</td>\n",
       "      <td>0.926161</td>\n",
       "      <td>0.007594</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.847234</td>\n",
       "      <td>0.862422</td>\n",
       "      <td>0.930631</td>\n",
       "      <td>0.937662</td>\n",
       "      <td>0.922728</td>\n",
       "      <td>0.929593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_modern</th>\n",
       "      <td>0.682965</td>\n",
       "      <td>0.858537</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.010909</td>\n",
       "      <td>0.004877</td>\n",
       "      <td>0.004791</td>\n",
       "      <td>0.672056</td>\n",
       "      <td>0.693874</td>\n",
       "      <td>0.853660</td>\n",
       "      <td>0.863414</td>\n",
       "      <td>0.835916</td>\n",
       "      <td>0.845499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>large_modern</th>\n",
       "      <td>0.826447</td>\n",
       "      <td>0.922561</td>\n",
       "      <td>0.912572</td>\n",
       "      <td>0.008298</td>\n",
       "      <td>0.003701</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>0.818149</td>\n",
       "      <td>0.834745</td>\n",
       "      <td>0.918860</td>\n",
       "      <td>0.926262</td>\n",
       "      <td>0.908934</td>\n",
       "      <td>0.916211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   MCC  Accuracy        F1    MCC_SE  Accuracy_SE     F1_SE  \\\n",
       "Column                                                                        \n",
       "base_nli      0.598784  0.828659  0.798812  0.012397     0.005373  0.005465   \n",
       "large_nli     0.720828  0.880488  0.850004  0.010343     0.004645  0.005080   \n",
       "base_debate   0.771101  0.896951  0.884403  0.009471     0.004323  0.004237   \n",
       "large_debate  0.854828  0.934146  0.926161  0.007594     0.003516  0.003433   \n",
       "base_modern   0.682965  0.858537  0.840708  0.010909     0.004877  0.004791   \n",
       "large_modern  0.826447  0.922561  0.912572  0.008298     0.003701  0.003638   \n",
       "\n",
       "              MCC_Lower  MCC_Upper  Accuracy_Lower  Accuracy_Upper  F1_Lower  \\\n",
       "Column                                                                         \n",
       "base_nli       0.586387   0.611181        0.823286        0.834032  0.793347   \n",
       "large_nli      0.710485   0.731171        0.875842        0.885133  0.844924   \n",
       "base_debate    0.761630   0.780572        0.892628        0.901274  0.880166   \n",
       "large_debate   0.847234   0.862422        0.930631        0.937662  0.922728   \n",
       "base_modern    0.672056   0.693874        0.853660        0.863414  0.835916   \n",
       "large_modern   0.818149   0.834745        0.918860        0.926262  0.908934   \n",
       "\n",
       "              F1_Upper  \n",
       "Column                  \n",
       "base_nli      0.804277  \n",
       "large_nli     0.855083  \n",
       "base_debate   0.888640  \n",
       "large_debate  0.929593  \n",
       "base_modern   0.845499  \n",
       "large_modern  0.916211  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Calculate performance metrics with bootstrapped standard errors. n_bootstrap == 1000\n",
    "overall = metrics_with_errors(ukp, columns, group_by = None)\n",
    "overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fb6bf16-ebf8-485a-a469-ead322e09e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukp.to_csv('../data/ukp_stance.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5299758-e786-49ca-852f-4f5dc15b1631",
   "metadata": {},
   "source": [
    "# UKP Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44e20c8e-97ca-44c7-857c-9b5ef2cf039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = pd.read_csv('../data/ukp_topic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3890f976-47ef-4458-81d2-317025afdc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_dict = [{'text':topic.loc[i, 'text'], 'text_pair':topic.loc[i, 'hypothesis']} for i in topic.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec6f2f4c-5b5f-40de-a5f5-b09e06eef8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models that will be tested\n",
    "models = [\"MoritzLaurer/deberta-v3-base-zeroshot-v2.0\", \n",
    "          \"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\",\n",
    "          \"mlburnham/Political_DEBATE_DeBERTa_base_v1.1\",\n",
    "          \"mlburnham/Political_DEBATE_DeBERTa_large_v1.1\",\n",
    "          \"mlburnham/Political_DEBATE_ModernBERT_base_v1.0\",\n",
    "          \"mlburnham/Political_DEBATE_ModernBERT_large_v1.0\"]\n",
    "\n",
    "# column names that will hold results\n",
    "columns = ['base_nli',\n",
    "           'large_nli',\n",
    "           'base_debate',\n",
    "           'large_debate',\n",
    "           'base_modern',\n",
    "           'large_modern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7c3e984-7897-45c9-a4f5-9ce880a24269",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "<timed exec>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoritzLaurer/deberta-v3-base-zeroshot-v2.0 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "<timed exec>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoritzLaurer/deberta-v3-large-zeroshot-v2.0 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "<timed exec>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlburnham/Political_DEBATE_DeBERTa_base_v1.1 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "<timed exec>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlburnham/Political_DEBATE_DeBERTa_large_v1.1 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlburnham/Political_DEBATE_ModernBERT_base_v1.0 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlburnham/Political_DEBATE_ModernBERT_large_v1.0 complete.\n",
      "CPU times: user 1min 21s, sys: 9.61 s, total: 1min 31s\n",
      "Wall time: 1min 24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# for each model, classify documents and return labels to the test dataframe\n",
    "for modname, col in zip(models, columns):\n",
    "    res = label_docs(modname, docs_dict, batch_size = 8, device = 'cuda')\n",
    "    topic[col] = res\n",
    "    topic[col] = topic[col].replace({'entailment': 0, 'not_entailment': 1})\n",
    "    print(modname + ' complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4addf2af-d8fe-4ec9-ad2f-c525f9d2fd86",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.8 s, sys: 0 ns, total: 11.8 s\n",
      "Wall time: 10.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MCC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>MCC_SE</th>\n",
       "      <th>Accuracy_SE</th>\n",
       "      <th>F1_SE</th>\n",
       "      <th>MCC_Lower</th>\n",
       "      <th>MCC_Upper</th>\n",
       "      <th>Accuracy_Lower</th>\n",
       "      <th>Accuracy_Upper</th>\n",
       "      <th>F1_Lower</th>\n",
       "      <th>F1_Upper</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base_nli</th>\n",
       "      <td>0.834676</td>\n",
       "      <td>0.911077</td>\n",
       "      <td>0.910410</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.829841</td>\n",
       "      <td>0.839510</td>\n",
       "      <td>0.908261</td>\n",
       "      <td>0.913893</td>\n",
       "      <td>0.907554</td>\n",
       "      <td>0.913267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>large_nli</th>\n",
       "      <td>0.838045</td>\n",
       "      <td>0.912602</td>\n",
       "      <td>0.911932</td>\n",
       "      <td>0.004617</td>\n",
       "      <td>0.002718</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>0.833428</td>\n",
       "      <td>0.842662</td>\n",
       "      <td>0.909884</td>\n",
       "      <td>0.915319</td>\n",
       "      <td>0.909178</td>\n",
       "      <td>0.914686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_debate</th>\n",
       "      <td>0.903384</td>\n",
       "      <td>0.951626</td>\n",
       "      <td>0.951622</td>\n",
       "      <td>0.004298</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.899085</td>\n",
       "      <td>0.907682</td>\n",
       "      <td>0.949473</td>\n",
       "      <td>0.953780</td>\n",
       "      <td>0.949468</td>\n",
       "      <td>0.953777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>large_debate</th>\n",
       "      <td>0.933844</td>\n",
       "      <td>0.966463</td>\n",
       "      <td>0.966447</td>\n",
       "      <td>0.003466</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>0.930378</td>\n",
       "      <td>0.937310</td>\n",
       "      <td>0.964683</td>\n",
       "      <td>0.968243</td>\n",
       "      <td>0.964665</td>\n",
       "      <td>0.968229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_modern</th>\n",
       "      <td>0.894691</td>\n",
       "      <td>0.946646</td>\n",
       "      <td>0.946605</td>\n",
       "      <td>0.004396</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.890295</td>\n",
       "      <td>0.899087</td>\n",
       "      <td>0.944392</td>\n",
       "      <td>0.948901</td>\n",
       "      <td>0.944347</td>\n",
       "      <td>0.948862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>large_modern</th>\n",
       "      <td>0.922943</td>\n",
       "      <td>0.960976</td>\n",
       "      <td>0.960955</td>\n",
       "      <td>0.003856</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>0.919087</td>\n",
       "      <td>0.926799</td>\n",
       "      <td>0.959000</td>\n",
       "      <td>0.962951</td>\n",
       "      <td>0.958978</td>\n",
       "      <td>0.962932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   MCC  Accuracy        F1    MCC_SE  Accuracy_SE     F1_SE  \\\n",
       "Column                                                                        \n",
       "base_nli      0.834676  0.911077  0.910410  0.004835     0.002816  0.002857   \n",
       "large_nli     0.838045  0.912602  0.911932  0.004617     0.002718  0.002754   \n",
       "base_debate   0.903384  0.951626  0.951622  0.004298     0.002154  0.002154   \n",
       "large_debate  0.933844  0.966463  0.966447  0.003466     0.001780  0.001782   \n",
       "base_modern   0.894691  0.946646  0.946605  0.004396     0.002254  0.002258   \n",
       "large_modern  0.922943  0.960976  0.960955  0.003856     0.001976  0.001977   \n",
       "\n",
       "              MCC_Lower  MCC_Upper  Accuracy_Lower  Accuracy_Upper  F1_Lower  \\\n",
       "Column                                                                         \n",
       "base_nli       0.829841   0.839510        0.908261        0.913893  0.907554   \n",
       "large_nli      0.833428   0.842662        0.909884        0.915319  0.909178   \n",
       "base_debate    0.899085   0.907682        0.949473        0.953780  0.949468   \n",
       "large_debate   0.930378   0.937310        0.964683        0.968243  0.964665   \n",
       "base_modern    0.890295   0.899087        0.944392        0.948901  0.944347   \n",
       "large_modern   0.919087   0.926799        0.959000        0.962951  0.958978   \n",
       "\n",
       "              F1_Upper  \n",
       "Column                  \n",
       "base_nli      0.913267  \n",
       "large_nli     0.914686  \n",
       "base_debate   0.953777  \n",
       "large_debate  0.968229  \n",
       "base_modern   0.948862  \n",
       "large_modern  0.962932  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Calculate performance metrics with bootstrapped standard errors.\n",
    "overall = metrics_with_errors(topic, columns, group_by = None)\n",
    "overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d74ad32f-31cf-4d92-9a2a-10cb90ebd6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic.to_csv('../data/ukp_topic.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8f56c2-f090-4f20-a40d-898ad378495d",
   "metadata": {},
   "source": [
    "# RAND Terrorism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34b457a0-34d4-4cae-98e9-c27bf9707734",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = pd.read_csv('../data/rand_terror.csv')\n",
    "\n",
    "# models that will be tested\n",
    "models = [\"MoritzLaurer/deberta-v3-base-zeroshot-v2.0\", \n",
    "          \"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\",\n",
    "          \"mlburnham/Political_DEBATE_DeBERTa_base_v1.1\",\n",
    "          \"mlburnham/Political_DEBATE_DeBERTa_large_v1.1\",\n",
    "          \"mlburnham/Political_DEBATE_ModernBERT_base_v1.0\",\n",
    "          \"mlburnham/Political_DEBATE_ModernBERT_large_v1.0\"]\n",
    "\n",
    "# column names that will hold results\n",
    "columns = ['base_nli',\n",
    "           'large_nli',\n",
    "           'base_debate',\n",
    "           'large_debate',\n",
    "           'base_modern',\n",
    "           'large_modern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2807bf2-672e-4ca4-ac8d-e30548b0f1cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoritzLaurer/deberta-v3-base-zeroshot-v2.0 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoritzLaurer/deberta-v3-large-zeroshot-v2.0 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlburnham/Political_DEBATE_DeBERTa_base_v1.1 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n",
      "Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in ModernBertForSequenceClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16)`\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlburnham/Political_DEBATE_DeBERTa_large_v1.1 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/miniforge3/envs/modern/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:198: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n",
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlburnham/Political_DEBATE_ModernBERT_base_v1.0 complete.\n",
      "mlburnham/Political_DEBATE_ModernBERT_large_v1.0 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_848/1952045164.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  rand[columns].replace({'This text describes an explosives attack.': 1,\n",
      "/tmp/ipykernel_848/1952045164.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rand[columns].replace({'This text describes an explosives attack.': 1,\n"
     ]
    }
   ],
   "source": [
    "for modname, col in zip(models, columns):\n",
    "    pipe = pipeline(task = 'zero-shot-classification', model = modname, \n",
    "                        batch_size = 16, device = 'cuda', \n",
    "                        max_length = 512, truncation = True)\n",
    "    \n",
    "    labels = list(rand['hypothesis'].unique())\n",
    "    \n",
    "    res = pipe(list(rand['premise']), candidate_labels = labels, template = {})\n",
    "    res = [result['labels'][0] for result in res]\n",
    "    rand[col] = res\n",
    "    print(modname + ' complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a3edcdd-c5a5-4419-9a12-4e57aa6faefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_848/1154416774.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  rand[col].replace({'This text describes an explosives attack.': 1,\n",
      "/tmp/ipykernel_848/1154416774.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  rand[col].replace({'This text describes an explosives attack.': 1,\n"
     ]
    }
   ],
   "source": [
    "for col in columns:\n",
    "    rand[col].replace({'This text describes an explosives attack.': 1,\n",
    "       'This text describes a firearms attack.': 2,\n",
    "       'This text describes an arson attack.': 3,\n",
    "       'This text describes a knife or sharp object attack.': 4,\n",
    "       'This text describes a biological agent attack.': 5,\n",
    "       'This text describes a chemical agent attack.': 6}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b0b1dc2-07f5-4896-a0d7-dbc339e8f51a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MCC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>MCC_SE</th>\n",
       "      <th>Accuracy_SE</th>\n",
       "      <th>F1_SE</th>\n",
       "      <th>MCC_Lower</th>\n",
       "      <th>MCC_Upper</th>\n",
       "      <th>Accuracy_Lower</th>\n",
       "      <th>Accuracy_Upper</th>\n",
       "      <th>F1_Lower</th>\n",
       "      <th>F1_Upper</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base_nli</th>\n",
       "      <td>0.842392</td>\n",
       "      <td>0.915979</td>\n",
       "      <td>0.858181</td>\n",
       "      <td>0.011531</td>\n",
       "      <td>0.006337</td>\n",
       "      <td>0.006656</td>\n",
       "      <td>0.830860</td>\n",
       "      <td>0.853923</td>\n",
       "      <td>0.909642</td>\n",
       "      <td>0.922316</td>\n",
       "      <td>0.851524</td>\n",
       "      <td>0.864837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>large_nli</th>\n",
       "      <td>0.936551</td>\n",
       "      <td>0.967010</td>\n",
       "      <td>0.915826</td>\n",
       "      <td>0.007486</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.004038</td>\n",
       "      <td>0.929066</td>\n",
       "      <td>0.944037</td>\n",
       "      <td>0.963087</td>\n",
       "      <td>0.970933</td>\n",
       "      <td>0.911789</td>\n",
       "      <td>0.919864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_debate</th>\n",
       "      <td>0.919739</td>\n",
       "      <td>0.958247</td>\n",
       "      <td>0.905951</td>\n",
       "      <td>0.008338</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>0.911401</td>\n",
       "      <td>0.928076</td>\n",
       "      <td>0.953752</td>\n",
       "      <td>0.962743</td>\n",
       "      <td>0.900935</td>\n",
       "      <td>0.910968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>large_debate</th>\n",
       "      <td>0.940040</td>\n",
       "      <td>0.968041</td>\n",
       "      <td>0.939939</td>\n",
       "      <td>0.007238</td>\n",
       "      <td>0.003913</td>\n",
       "      <td>0.003881</td>\n",
       "      <td>0.932802</td>\n",
       "      <td>0.947277</td>\n",
       "      <td>0.964128</td>\n",
       "      <td>0.971954</td>\n",
       "      <td>0.936059</td>\n",
       "      <td>0.943820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_modern</th>\n",
       "      <td>0.727122</td>\n",
       "      <td>0.847938</td>\n",
       "      <td>0.634377</td>\n",
       "      <td>0.012973</td>\n",
       "      <td>0.007935</td>\n",
       "      <td>0.007155</td>\n",
       "      <td>0.714149</td>\n",
       "      <td>0.740095</td>\n",
       "      <td>0.840003</td>\n",
       "      <td>0.855873</td>\n",
       "      <td>0.627222</td>\n",
       "      <td>0.641532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>large_modern</th>\n",
       "      <td>0.866921</td>\n",
       "      <td>0.929897</td>\n",
       "      <td>0.833755</td>\n",
       "      <td>0.010945</td>\n",
       "      <td>0.005879</td>\n",
       "      <td>0.005995</td>\n",
       "      <td>0.855975</td>\n",
       "      <td>0.877866</td>\n",
       "      <td>0.924017</td>\n",
       "      <td>0.935776</td>\n",
       "      <td>0.827760</td>\n",
       "      <td>0.839750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   MCC  Accuracy        F1    MCC_SE  Accuracy_SE     F1_SE  \\\n",
       "Column                                                                        \n",
       "base_nli      0.842392  0.915979  0.858181  0.011531     0.006337  0.006656   \n",
       "large_nli     0.936551  0.967010  0.915826  0.007486     0.003923  0.004038   \n",
       "base_debate   0.919739  0.958247  0.905951  0.008338     0.004496  0.005017   \n",
       "large_debate  0.940040  0.968041  0.939939  0.007238     0.003913  0.003881   \n",
       "base_modern   0.727122  0.847938  0.634377  0.012973     0.007935  0.007155   \n",
       "large_modern  0.866921  0.929897  0.833755  0.010945     0.005879  0.005995   \n",
       "\n",
       "              MCC_Lower  MCC_Upper  Accuracy_Lower  Accuracy_Upper  F1_Lower  \\\n",
       "Column                                                                         \n",
       "base_nli       0.830860   0.853923        0.909642        0.922316  0.851524   \n",
       "large_nli      0.929066   0.944037        0.963087        0.970933  0.911789   \n",
       "base_debate    0.911401   0.928076        0.953752        0.962743  0.900935   \n",
       "large_debate   0.932802   0.947277        0.964128        0.971954  0.936059   \n",
       "base_modern    0.714149   0.740095        0.840003        0.855873  0.627222   \n",
       "large_modern   0.855975   0.877866        0.924017        0.935776  0.827760   \n",
       "\n",
       "              F1_Upper  \n",
       "Column                  \n",
       "base_nli      0.864837  \n",
       "large_nli     0.919864  \n",
       "base_debate   0.910968  \n",
       "large_debate  0.943820  \n",
       "base_modern   0.641532  \n",
       "large_modern  0.839750  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall = metrics_with_errors(rand, columns, group_by = None)\n",
    "overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "172671fb-0b45-4c81-b3bb-ecf6ed82d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand.to_csv('../data/rand_terror.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
