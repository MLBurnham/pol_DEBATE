{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58833a02-0bd6-4414-b130-225bd714d0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikeb\\.conda\\envs\\sandbox\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#from datasets import load_from_disk # import if using a huggingface dataset saved locally\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "import gc\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "#from accelerate.utils import release_memory\n",
    "import numpy as np\n",
    "from sklearn.metrics import balanced_accuracy_score, precision_recall_fscore_support, accuracy_score, classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe20b867-1dfc-4ccc-80de-2c5a9cb7f134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_PROJECT\"] = \"Pol-NLI-Large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1e7c3d3-11e4-4deb-aba8-6050b2a29cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "modname = \"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\"\n",
    "modname = 'training_large/latest_checkpoint'\n",
    "training_directory ='training_large'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb2be10a-fcef-4a9c-96c1-0a4c70595897",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"mlburnham/Pol_NLI\")\n",
    "#ds = ds.shuffle(seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c244daf-ca6d-48c6-9e07-3036ce5c58d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds['train'].to_pandas()\n",
    "dftest = ds['test'].to_pandas()\n",
    "dfval = ds['validation'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5113b507-8f62-4fa0-a8e8-d623e68c88b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, dftest, dfval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed91dd9f-519e-41e7-ba39-f214975ded3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2834"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['augmented_hypothesis'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07078043-3ef2-46e6-aaff-e93f5db209b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate(text):\n",
    "    words = text.split()\n",
    "    if len(words) > 450:\n",
    "        return \" \".join(words[:450])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69e16968-a8df-43fa-b59f-ff0ef369bde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['premise'] = df['premise'].apply(truncate)\n",
    "dftest['premise'] = dftest['premise'].apply(truncate)\n",
    "dfval['premise'] = dfval['premise'].apply(truncate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fed860b-def3-45e8-9f37-e65081bfd522",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DatasetDict({'train': Dataset.from_pandas(df, preserve_index=False), 'validation':Dataset.from_pandas(dfval, preserve_index=False), 'test':Dataset.from_pandas(dftest, preserve_index=False)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56f01a7f-96e6-41be-a6ba-0d10653da44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(modname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b957755c-05bb-4a11-b58e-8644b8af43ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(docs):\n",
    "    #return tokenizer(docs['premise'], docs['augmented_hypothesis'], padding = 'max_length', truncation = True)\n",
    "    return tokenizer(docs['premise'], docs['augmented_hypothesis'], padding = True, truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0589f9d1-9ab1-4777-9faa-6756a4519cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 171289/171289 [00:33<00:00, 5102.23 examples/s]\n",
      "Map: 100%|██████████| 15036/15036 [00:02<00:00, 5328.73 examples/s]\n",
      "Map: 100%|██████████| 15366/15366 [00:02<00:00, 5606.16 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dstok = ds.map(tokenize_function, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8df91381-6176-4d83-b765-412a54e25573",
   "metadata": {},
   "outputs": [],
   "source": [
    "dstok = dstok.rename_columns({'entailment':'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f7eb56b-1103-4851-a55f-4f001f40b13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"entailment\", 1: \"not_entailment\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d11db7a1-e27d-42e2-acd2-40fcccd720ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(modname, num_labels = 2, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dde4dc9-b4df-430d-bb43-4af6079d9eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=training_directory,\n",
    "    logging_dir=f'{training_directory}/logs',\n",
    "    #deepspeed=\"ds_config_zero3.json\",  # if using deepspeed\n",
    "    lr_scheduler_type= \"linear\",\n",
    "    group_by_length=False,  # can increase speed with dynamic padding, by grouping similar length texts https://huggingface.co/transformers/main_classes/trainer.html\n",
    "    learning_rate=9e-6 if \"large\" in modname else 2e-5,\n",
    "    per_device_train_batch_size=4 if \"large\" in modname else 8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=4 if \"large\" in modname else 2,  # (!adapt/halve batch size accordingly). accumulates gradients over X steps, only then backward/update. decreases memory usage, but also slightly speed\n",
    "    #eval_accumulation_steps=2,\n",
    "    num_train_epochs=20,\n",
    "    #max_steps=400,\n",
    "    #warmup_steps=0,  # 1000,\n",
    "    warmup_ratio=0.06,  #0.1, 0.06\n",
    "    weight_decay=0.01,  #0.1,\n",
    "    fp16=True,   # ! only makes sense at batch-size > 8. loads two copies of model weights, which creates overhead. https://huggingface.co/transformers/performance.html?#fp16\n",
    "    fp16_full_eval=True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    seed=1,\n",
    "    #load_best_model_at_end=True,\n",
    "    #metric_for_best_model=\"accuracy\",\n",
    "    #eval_steps=50,  # evaluate after n steps if evaluation_strategy!='steps'. defaults to logging_steps\n",
    "    save_strategy=\"epoch\",  # options: \"no\"/\"steps\"/\"epoch\"\n",
    "    #save_steps=100,  # Number of updates steps before two checkpoint saves.\n",
    "    dataloader_num_workers = 12,\n",
    "    #save_total_limit=1,  # If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in output_dir\n",
    "    #logging_strategy=\"epoch\",\n",
    "    #report_to=\"all\",  # \"all\"\n",
    "    #run_name=run_name,\n",
    "    #push_to_hub=True,  # does not seem to work if save_strategy=\"no\"\n",
    "    #hub_model_id=hub_model_id,\n",
    "    #hub_token=config.HF_ACCESS_TOKEN,\n",
    "    #hub_strategy=\"end\",\n",
    "    #hub_private_repo=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2f90579-4df2-4014-b04b-5b503f68f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_standard(eval_pred, label_text_alphabetical=list(model.config.id2label.values())):\n",
    "    labels = eval_pred.label_ids\n",
    "    pred_logits = eval_pred.predictions\n",
    "    preds_max = np.argmax(pred_logits, axis=1)  # argmax on each row (axis=1) in the tensor\n",
    "\n",
    "    # metrics\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(labels, preds_max, average='macro')  # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(labels, preds_max, average='micro')  # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n",
    "    acc_balanced = balanced_accuracy_score(labels, preds_max)\n",
    "    acc_not_balanced = accuracy_score(labels, preds_max)\n",
    "\n",
    "    metrics = {'f1_macro': f1_macro,\n",
    "            'f1_micro': f1_micro,\n",
    "            'accuracy_balanced': acc_balanced,\n",
    "            'accuracy': acc_not_balanced,\n",
    "            'precision_macro': precision_macro,\n",
    "            'recall_macro': recall_macro,\n",
    "            'precision_micro': precision_micro,\n",
    "            'recall_micro': recall_micro,\n",
    "            #'label_gold_raw': labels,\n",
    "            #'label_predicted_raw': preds_max\n",
    "            }\n",
    "    print(\"Aggregate metrics: \", {key: metrics[key] for key in metrics if key not in [\"label_gold_raw\", \"label_predicted_raw\"]} )  # print metrics but without label lists\n",
    "    print(\"Detailed metrics: \", classification_report(\n",
    "        labels, preds_max, labels=np.sort(pd.factorize(label_text_alphabetical, sort=True)[0]),\n",
    "        target_names=label_text_alphabetical, sample_weight=None,\n",
    "        digits=2, output_dict=True, zero_division='warn'),\n",
    "    \"\\n\")\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8e7ae80-6451-42fd-97b3-d8e49218c962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikeb\\.conda\\envs\\sandbox\\Lib\\site-packages\\accelerate\\accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    #model_init=model_init,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=dstok['train'],\n",
    "    eval_dataset=dstok['validation'],\n",
    "    compute_metrics=lambda x: compute_metrics_standard(x, label_text_alphabetical=list(model.config.id2label.values()))  #compute_metrics,\n",
    "    #data_collator=data_collator,  # for weighted sampling per dataset; for dynamic padding probably not necessary because done by default  https://huggingface.co/course/chapter3/3?fw=pt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19e820e-b440-47e2-8dc4-2f54c889408a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikeb\\.conda\\envs\\sandbox\\Lib\\site-packages\\transformers\\trainer.py:3098: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "wandb: Currently logged in as: mlburnham. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\mikeb\\OneDrive - The Pennsylvania State University\\PoliStance\\wandb\\run-20240809_213327-3glaxuas</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mlburnham/Pol-NLI-Large/runs/3glaxuas' target=\"_blank\">training_large</a></strong> to <a href='https://wandb.ai/mlburnham/Pol-NLI-Large' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mlburnham/Pol-NLI-Large' target=\"_blank\">https://wandb.ai/mlburnham/Pol-NLI-Large</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mlburnham/Pol-NLI-Large/runs/3glaxuas' target=\"_blank\">https://wandb.ai/mlburnham/Pol-NLI-Large/runs/3glaxuas</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikeb\\.conda\\envs\\sandbox\\Lib\\site-packages\\transformers\\trainer.py:2833: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='137104' max='214100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [137104/214100 11:48:16 < 22:18:14, 0.96 it/s, Epoch 12.81/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>Accuracy Balanced</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>Precision Micro</th>\n",
       "      <th>Recall Micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.336436</td>\n",
       "      <td>0.958684</td>\n",
       "      <td>0.959830</td>\n",
       "      <td>0.957256</td>\n",
       "      <td>0.959830</td>\n",
       "      <td>0.960308</td>\n",
       "      <td>0.957256</td>\n",
       "      <td>0.959830</td>\n",
       "      <td>0.959830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.435559</td>\n",
       "      <td>0.950781</td>\n",
       "      <td>0.952248</td>\n",
       "      <td>0.948499</td>\n",
       "      <td>0.952248</td>\n",
       "      <td>0.953582</td>\n",
       "      <td>0.948499</td>\n",
       "      <td>0.952248</td>\n",
       "      <td>0.952248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.409473</td>\n",
       "      <td>0.951548</td>\n",
       "      <td>0.952913</td>\n",
       "      <td>0.949951</td>\n",
       "      <td>0.952913</td>\n",
       "      <td>0.953397</td>\n",
       "      <td>0.949951</td>\n",
       "      <td>0.952913</td>\n",
       "      <td>0.952913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate metrics:  {'f1_macro': 0.9586839037559856, 'f1_micro': 0.959829741952647, 'accuracy_balanced': 0.9572557427285473, 'accuracy': 0.959829741952647, 'precision_macro': 0.9603081722406619, 'recall_macro': 0.9572557427285473, 'precision_micro': 0.959829741952647, 'recall_micro': 0.959829741952647}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikeb\\AppData\\Local\\Temp\\ipykernel_20300\\1657252757.py:25: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  labels, preds_max, labels=np.sort(pd.factorize(label_text_alphabetical, sort=True)[0]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed metrics:  {'entailment': {'precision': 0.9630227676408849, 'recall': 0.9408424041646948, 'f1-score': 0.951803383338653, 'support': 6339.0}, 'not_entailment': {'precision': 0.9575935768404388, 'recall': 0.9736690812923997, 'f1-score': 0.9655644241733181, 'support': 8697.0}, 'accuracy': 0.959829741952647, 'macro avg': {'precision': 0.9603081722406619, 'recall': 0.9572557427285473, 'f1-score': 0.9586839037559856, 'support': 15036.0}, 'weighted avg': {'precision': 0.9598824595541943, 'recall': 0.959829741952647, 'f1-score': 0.9597629318980494, 'support': 15036.0}} \n",
      "\n",
      "Aggregate metrics:  {'f1_macro': 0.9507807712956857, 'f1_micro': 0.9522479382814578, 'accuracy_balanced': 0.9484990309228052, 'accuracy': 0.9522479382814578, 'precision_macro': 0.9535823523568522, 'recall_macro': 0.9484990309228052, 'precision_micro': 0.9522479382814578, 'recall_micro': 0.9522479382814578}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikeb\\AppData\\Local\\Temp\\ipykernel_20300\\1657252757.py:25: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  labels, preds_max, labels=np.sort(pd.factorize(label_text_alphabetical, sort=True)[0]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed metrics:  {'entailment': {'precision': 0.9606621865267989, 'recall': 0.9245937845085975, 'f1-score': 0.9422829581993569, 'support': 6339.0}, 'not_entailment': {'precision': 0.9465025181869055, 'recall': 0.9724042773370127, 'f1-score': 0.9592785843920145, 'support': 8697.0}, 'accuracy': 0.9522479382814578, 'macro avg': {'precision': 0.9535823523568522, 'recall': 0.9484990309228052, 'f1-score': 0.9507807712956857, 'support': 15036.0}, 'weighted avg': {'precision': 0.9524720671099292, 'recall': 0.9522479382814578, 'f1-score': 0.9521134291356128, 'support': 15036.0}} \n",
      "\n",
      "Aggregate metrics:  {'f1_macro': 0.9515477078223584, 'f1_micro': 0.9529130087789306, 'accuracy_balanced': 0.9499507557398172, 'accuracy': 0.9529130087789306, 'precision_macro': 0.9533965186971707, 'recall_macro': 0.9499507557398172, 'precision_micro': 0.9529130087789306, 'recall_micro': 0.9529130087789306}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikeb\\AppData\\Local\\Temp\\ipykernel_20300\\1657252757.py:25: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  labels, preds_max, labels=np.sort(pd.factorize(label_text_alphabetical, sort=True)[0]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed metrics:  {'entailment': {'precision': 0.956099141422323, 'recall': 0.9310616816532576, 'f1-score': 0.9434143222506394, 'support': 6339.0}, 'not_entailment': {'precision': 0.9506938959720185, 'recall': 0.968839829826377, 'f1-score': 0.9596810933940775, 'support': 8697.0}, 'accuracy': 0.9529130087789306, 'macro avg': {'precision': 0.9533965186971707, 'recall': 0.9499507557398172, 'f1-score': 0.9515477078223584, 'support': 15036.0}, 'weighted avg': {'precision': 0.9529726836089885, 'recall': 0.9529130087789306, 'f1-score': 0.9528232148174445, 'support': 15036.0}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#trainer.train()\n",
    "trainer.train(resume_from_checkpoint = 'training_large/latest_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7354294-8ffa-40f8-bb53-6493431392d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate metrics:  {'f1_macro': 0.9483667829600351, 'f1_micro': 0.950475074840557, 'accuracy_balanced': 0.9449757064506679, 'accuracy': 0.950475074840557, 'precision_macro': 0.9526335862387606, 'recall_macro': 0.9449757064506679, 'precision_micro': 0.950475074840557, 'recall_micro': 0.950475074840557}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikeb\\AppData\\Local\\Temp\\ipykernel_21804\\1657252757.py:25: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  labels, preds_max, labels=np.sort(pd.factorize(label_text_alphabetical, sort=True)[0]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed metrics:  {'entailment': {'precision': 0.9623430962343096, 'recall': 0.9147311485841553, 'f1-score': 0.9379332843976838, 'support': 6286.0}, 'not_entailment': {'precision': 0.9429240762432116, 'recall': 0.9752202643171806, 'f1-score': 0.9588002815223864, 'support': 9080.0}, 'accuracy': 0.950475074840557, 'macro avg': {'precision': 0.9526335862387606, 'recall': 0.9449757064506679, 'f1-score': 0.9483667829600351, 'support': 15366.0}, 'weighted avg': {'precision': 0.9508681058972558, 'recall': 0.950475074840557, 'f1-score': 0.9502639061530072, 'support': 15366.0}} \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.23196956515312195,\n",
       " 'eval_f1_macro': 0.9483667829600351,\n",
       " 'eval_f1_micro': 0.950475074840557,\n",
       " 'eval_accuracy_balanced': 0.9449757064506679,\n",
       " 'eval_accuracy': 0.950475074840557,\n",
       " 'eval_precision_macro': 0.9526335862387606,\n",
       " 'eval_recall_macro': 0.9449757064506679,\n",
       " 'eval_precision_micro': 0.950475074840557,\n",
       " 'eval_recall_micro': 0.950475074840557}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset = dstok['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5a139a1-a43f-403f-8b42-2d92a99dd921",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"training_large/test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
