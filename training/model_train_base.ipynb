{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58833a02-0bd6-4414-b130-225bd714d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from datasets import load_from_disk # import if using a huggingface dataset saved locally\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "import gc\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "#from accelerate.utils import release_memory\n",
    "import numpy as np\n",
    "from sklearn.metrics import balanced_accuracy_score, precision_recall_fscore_support, accuracy_score, classification_report, matthews_corrcoef\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe20b867-1dfc-4ccc-80de-2c5a9cb7f134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_PROJECT\"] = \"Pol-NLI-Base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1e7c3d3-11e4-4deb-aba8-6050b2a29cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "#modname = \"MoritzLaurer/deberta-v3-base-zeroshot-v1.1-all-33\"\n",
    "modname = \"MoritzLaurer/deberta-v3-base-zeroshot-v2.0\"\n",
    "training_directory ='training_base'\n",
    "#training_directory ='training_large'\n",
    "#training_directory = 'training_base'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb2be10a-fcef-4a9c-96c1-0a4c70595897",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"mlburnham/Pol_NLI\")\n",
    "#ds = ds.shuffle(seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c244daf-ca6d-48c6-9e07-3036ce5c58d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds['train'].to_pandas()\n",
    "dftest = ds['test'].to_pandas()\n",
    "dfval = ds['validation'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07078043-3ef2-46e6-aaff-e93f5db209b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate(text):\n",
    "    words = text.split()\n",
    "    if len(words) > 450:\n",
    "        return \" \".join(words[:450])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69e16968-a8df-43fa-b59f-ff0ef369bde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['premise'] = df['premise'].apply(truncate)\n",
    "dftest['premise'] = dftest['premise'].apply(truncate)\n",
    "dfval['premise'] = dfval['premise'].apply(truncate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fed860b-def3-45e8-9f37-e65081bfd522",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DatasetDict({'train': Dataset.from_pandas(df, preserve_index=False), 'validation':Dataset.from_pandas(dfval, preserve_index=False), 'test':Dataset.from_pandas(dftest, preserve_index=False)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56f01a7f-96e6-41be-a6ba-0d10653da44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(modname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86443032-5d54-4fab-9e5e-64adb0d0fece",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tokenize_function(docs):\n",
    "    return tokenizer(docs['premise'], docs['augmented_hypothesis'], padding = True, truncation = True)\n",
    "\n",
    "dstok = ds.map(tokenize_function, batched = True)\n",
    "\n",
    "dstok = dstok.rename_columns({'entailment':'label'})\n",
    "\n",
    "id2label = {0: \"entailment\", 1: \"not_entailment\"}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(modname, num_labels = 2, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dde4dc9-b4df-430d-bb43-4af6079d9eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=training_directory,\n",
    "    logging_dir=f'{training_directory}/logs',\n",
    "    #deepspeed=\"ds_config_zero3.json\",  # if using deepspeed\n",
    "    lr_scheduler_type= \"linear\",\n",
    "    group_by_length=True,  # can increase speed with dynamic padding, by grouping similar length texts https://huggingface.co/transformers/main_classes/trainer.html\n",
    "    learning_rate=9e-6 if \"large\" in modname else 2e-5,\n",
    "    per_device_train_batch_size=4 if \"large\" in modname else 4,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=4 if \"large\" in modname else 1,  # (!adapt/halve batch size accordingly). accumulates gradients over X steps, only then backward/update. decreases memory usage, but also slightly speed\n",
    "    #eval_accumulation_steps=2,\n",
    "    num_train_epochs=20,\n",
    "    #max_steps=400,\n",
    "    #warmup_steps=0,  # 1000,\n",
    "    warmup_ratio=0.06,  #0.1, 0.06\n",
    "    weight_decay=0.01,  #0.1,\n",
    "    fp16=True,   # ! only makes sense at batch-size > 8. loads two copies of model weights, which creates overhead. https://huggingface.co/transformers/performance.html?#fp16\n",
    "    fp16_full_eval=True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    seed=1,\n",
    "    #load_best_model_at_end=True,\n",
    "    #metric_for_best_model=\"accuracy\",\n",
    "    #eval_steps=50,  # evaluate after n steps if evaluation_strategy!='steps'. defaults to logging_steps\n",
    "    save_strategy=\"epoch\",  # options: \"no\"/\"steps\"/\"epoch\"\n",
    "    #save_steps=100,  # Number of updates steps before two checkpoint saves.\n",
    "    dataloader_num_workers = 12,\n",
    "    #save_total_limit=1,  # If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in output_dir\n",
    "    #logging_strategy=\"epoch\",\n",
    "    #report_to=\"all\",  # \"all\"\n",
    "    #run_name=run_name,\n",
    "    #push_to_hub=True,  # does not seem to work if save_strategy=\"no\"\n",
    "    #hub_model_id=hub_model_id,\n",
    "    #hub_token=config.HF_ACCESS_TOKEN,\n",
    "    #hub_strategy=\"end\",\n",
    "    #hub_private_repo=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2f90579-4df2-4014-b04b-5b503f68f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_standard(eval_pred, label_text_alphabetical=list(model.config.id2label.values())):\n",
    "    labels = eval_pred.label_ids\n",
    "    pred_logits = eval_pred.predictions\n",
    "    preds_max = np.argmax(pred_logits, axis=1)  # argmax on each row (axis=1) in the tensor\n",
    "\n",
    "    # metrics\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(labels, preds_max, average='macro')  # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(labels, preds_max, average='micro')  # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n",
    "    acc_balanced = balanced_accuracy_score(labels, preds_max)\n",
    "    acc_not_balanced = accuracy_score(labels, preds_max)\n",
    "    mcc = matthews_corrcoef(labels, preds_max)\n",
    "\n",
    "    metrics = {'MCC': mcc,\n",
    "            'f1_macro': f1_macro,\n",
    "            'f1_micro': f1_micro,\n",
    "            'accuracy_balanced': acc_balanced,\n",
    "            'accuracy': acc_not_balanced,\n",
    "            'precision_macro': precision_macro,\n",
    "            'recall_macro': recall_macro,\n",
    "            'precision_micro': precision_micro,\n",
    "            'recall_micro': recall_micro,\n",
    "            #'label_gold_raw': labels,\n",
    "            #'label_predicted_raw': preds_max\n",
    "            }\n",
    "    print(\"Aggregate metrics: \", {key: metrics[key] for key in metrics if key not in [\"label_gold_raw\", \"label_predicted_raw\"]} )  # print metrics but without label lists\n",
    "    print(\"Detailed metrics: \", classification_report(\n",
    "        labels, preds_max, labels=np.sort(pd.factorize(label_text_alphabetical, sort=True)[0]),\n",
    "        target_names=label_text_alphabetical, sample_weight=None,\n",
    "        digits=2, output_dict=True, zero_division='warn'),\n",
    "    \"\\n\")\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8e7ae80-6451-42fd-97b3-d8e49218c962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikeb\\.conda\\envs\\sandbox\\Lib\\site-packages\\accelerate\\accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    #model_init=model_init,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=dstok['train'],\n",
    "    eval_dataset=dstok['validation'],\n",
    "    compute_metrics=lambda x: compute_metrics_standard(x, label_text_alphabetical=list(model.config.id2label.values()))  #compute_metrics,\n",
    "    #data_collator=data_collator,  # for weighted sampling per dataset; for dynamic padding probably not necessary because done by default  https://huggingface.co/course/chapter3/3?fw=pt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d42768a-55ab-4074-8396-d85d96588fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == \"cuda\":\n",
    "    # free memory\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    release_memory(model)\n",
    "    #del (model, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b19e820e-b440-47e2-8dc4-2f54c889408a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "wandb: Currently logged in as: mlburnham. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\mikeb\\OneDrive - Princeton University\\PoliStance\\wandb\\run-20240812_002034-b3rguhjv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mlburnham/Pol-NLI-Base/runs/b3rguhjv' target=\"_blank\">training_base</a></strong> to <a href='https://wandb.ai/mlburnham/Pol-NLI-Base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mlburnham/Pol-NLI-Base' target=\"_blank\">https://wandb.ai/mlburnham/Pol-NLI-Base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mlburnham/Pol-NLI-Base/runs/b3rguhjv' target=\"_blank\">https://wandb.ai/mlburnham/Pol-NLI-Base/runs/b3rguhjv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='404315' max='856460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [404315/856460 11:08:46 < 12:27:53, 10.08 it/s, Epoch 9.44/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>Accuracy Balanced</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>Precision Micro</th>\n",
       "      <th>Recall Micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>0.289279</td>\n",
       "      <td>0.858225</td>\n",
       "      <td>0.928839</td>\n",
       "      <td>0.930234</td>\n",
       "      <td>0.931180</td>\n",
       "      <td>0.930234</td>\n",
       "      <td>0.927055</td>\n",
       "      <td>0.931180</td>\n",
       "      <td>0.930234</td>\n",
       "      <td>0.930234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.214500</td>\n",
       "      <td>0.303717</td>\n",
       "      <td>0.878449</td>\n",
       "      <td>0.939175</td>\n",
       "      <td>0.940809</td>\n",
       "      <td>0.938183</td>\n",
       "      <td>0.940809</td>\n",
       "      <td>0.940269</td>\n",
       "      <td>0.938183</td>\n",
       "      <td>0.940809</td>\n",
       "      <td>0.940809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.171800</td>\n",
       "      <td>0.396141</td>\n",
       "      <td>0.863504</td>\n",
       "      <td>0.931616</td>\n",
       "      <td>0.933559</td>\n",
       "      <td>0.929992</td>\n",
       "      <td>0.933559</td>\n",
       "      <td>0.933520</td>\n",
       "      <td>0.929992</td>\n",
       "      <td>0.933559</td>\n",
       "      <td>0.933559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>0.386189</td>\n",
       "      <td>0.879039</td>\n",
       "      <td>0.939086</td>\n",
       "      <td>0.941008</td>\n",
       "      <td>0.936174</td>\n",
       "      <td>0.941008</td>\n",
       "      <td>0.942890</td>\n",
       "      <td>0.936174</td>\n",
       "      <td>0.941008</td>\n",
       "      <td>0.941008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.352744</td>\n",
       "      <td>0.889709</td>\n",
       "      <td>0.944841</td>\n",
       "      <td>0.946262</td>\n",
       "      <td>0.944309</td>\n",
       "      <td>0.946262</td>\n",
       "      <td>0.945401</td>\n",
       "      <td>0.944309</td>\n",
       "      <td>0.946262</td>\n",
       "      <td>0.946262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.053400</td>\n",
       "      <td>0.475702</td>\n",
       "      <td>0.868469</td>\n",
       "      <td>0.933148</td>\n",
       "      <td>0.935555</td>\n",
       "      <td>0.928637</td>\n",
       "      <td>0.935555</td>\n",
       "      <td>0.939906</td>\n",
       "      <td>0.928637</td>\n",
       "      <td>0.935555</td>\n",
       "      <td>0.935555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.528699</td>\n",
       "      <td>0.868221</td>\n",
       "      <td>0.933490</td>\n",
       "      <td>0.935688</td>\n",
       "      <td>0.930056</td>\n",
       "      <td>0.935688</td>\n",
       "      <td>0.938203</td>\n",
       "      <td>0.930056</td>\n",
       "      <td>0.935688</td>\n",
       "      <td>0.935688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.529357</td>\n",
       "      <td>0.882424</td>\n",
       "      <td>0.941016</td>\n",
       "      <td>0.942737</td>\n",
       "      <td>0.939037</td>\n",
       "      <td>0.942737</td>\n",
       "      <td>0.943397</td>\n",
       "      <td>0.939037</td>\n",
       "      <td>0.942737</td>\n",
       "      <td>0.942737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.046500</td>\n",
       "      <td>0.507311</td>\n",
       "      <td>0.888016</td>\n",
       "      <td>0.943957</td>\n",
       "      <td>0.945464</td>\n",
       "      <td>0.942934</td>\n",
       "      <td>0.945464</td>\n",
       "      <td>0.945084</td>\n",
       "      <td>0.942934</td>\n",
       "      <td>0.945464</td>\n",
       "      <td>0.945464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate metrics:  {'MCC': 0.8582253579934088, 'f1_macro': 0.9288394102617632, 'f1_micro': 0.9302341048151104, 'accuracy_balanced': 0.9311803369483882, 'accuracy': 0.9302341048151104, 'precision_macro': 0.9270549361757414, 'recall_macro': 0.9311803369483882, 'precision_micro': 0.9302341048151104, 'recall_micro': 0.9302341048151104}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikeb\\AppData\\Local\\Temp\\ipykernel_16576\\1338913006.py:27: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  labels, preds_max, labels=np.sort(pd.factorize(label_text_alphabetical, sort=True)[0]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed metrics:  {'entailment': {'precision': 0.9012439320388349, 'recall': 0.9372140716201294, 'f1-score': 0.9188771170056453, 'support': 6339.0}, 'not_entailment': {'precision': 0.952865940312648, 'recall': 0.9251466022766471, 'f1-score': 0.9388017035178811, 'support': 8697.0}, 'accuracy': 0.9302341048151104, 'macro avg': {'precision': 0.9270549361757414, 'recall': 0.9311803369483882, 'f1-score': 0.9288394102617632, 'support': 15036.0}, 'weighted avg': {'precision': 0.9311027113656075, 'recall': 0.9302341048151104, 'f1-score': 0.9304017331866054, 'support': 15036.0}} \n",
      "\n",
      "Aggregate metrics:  {'MCC': 0.8784490297347349, 'f1_macro': 0.9391753102131721, 'f1_micro': 0.9408087257249268, 'accuracy_balanced': 0.9381828495239177, 'accuracy': 0.9408087257249268, 'precision_macro': 0.9402686564982596, 'recall_macro': 0.9381828495239177, 'precision_micro': 0.9408087257249268, 'recall_micro': 0.9408087257249268}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikeb\\AppData\\Local\\Temp\\ipykernel_16576\\1338913006.py:27: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  labels, preds_max, labels=np.sort(pd.factorize(label_text_alphabetical, sort=True)[0]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed metrics:  {'entailment': {'precision': 0.9371089363067544, 'recall': 0.9214387127307146, 'f1-score': 0.9292077632834871, 'support': 6339.0}, 'not_entailment': {'precision': 0.9434283766897649, 'recall': 0.9549269863171208, 'f1-score': 0.9491428571428572, 'support': 8697.0}, 'accuracy': 0.9408087257249268, 'macro avg': {'precision': 0.9402686564982596, 'recall': 0.9381828495239177, 'f1-score': 0.9391753102131721, 'support': 15036.0}, 'weighted avg': {'precision': 0.9407641752673185, 'recall': 0.9408087257249268, 'f1-score': 0.9407384570381387, 'support': 15036.0}} \n",
      "\n",
      "Aggregate metrics:  {'MCC': 0.8635043434451539, 'f1_macro': 0.9316156739217735, 'f1_micro': 0.933559457302474, 'accuracy_balanced': 0.9299916073349379, 'accuracy': 0.933559457302474, 'precision_macro': 0.9335199445926845, 'recall_macro': 0.9299916073349379, 'precision_micro': 0.933559457302474, 'recall_micro': 0.933559457302474}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikeb\\AppData\\Local\\Temp\\ipykernel_16576\\1338913006.py:27: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  labels, preds_max, labels=np.sort(pd.factorize(label_text_alphabetical, sort=True)[0]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed metrics:  {'entailment': {'precision': 0.9333008763388511, 'recall': 0.9072408897302414, 'f1-score': 0.9200863930885529, 'support': 6339.0}, 'not_entailment': {'precision': 0.933739012846518, 'recall': 0.9527423249396344, 'f1-score': 0.943144954754994, 'support': 8697.0}, 'accuracy': 0.933559457302474, 'macro avg': {'precision': 0.9335199445926845, 'recall': 0.9299916073349379, 'f1-score': 0.9316156739217735, 'support': 15036.0}, 'weighted avg': {'precision': 0.9335542996700015, 'recall': 0.933559457302474, 'f1-score': 0.9334237375161293, 'support': 15036.0}} \n",
      "\n",
      "Aggregate metrics:  {'MCC': 0.8790385115953533, 'f1_macro': 0.9390860406868684, 'f1_micro': 0.9410082468741686, 'accuracy_balanced': 0.9361739808228446, 'accuracy': 0.9410082468741686, 'precision_macro': 0.9428901876551959, 'recall_macro': 0.9361739808228446, 'precision_micro': 0.9410082468741686, 'recall_micro': 0.9410082468741686}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikeb\\AppData\\Local\\Temp\\ipykernel_16576\\1338913006.py:27: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  labels, preds_max, labels=np.sort(pd.factorize(label_text_alphabetical, sort=True)[0]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed metrics:  {'entailment': {'precision': 0.9523730501161632, 'recall': 0.9053478466635116, 'f1-score': 0.9282652648604933, 'support': 6339.0}, 'not_entailment': {'precision': 0.9334073251942286, 'recall': 0.9670001149821777, 'f1-score': 0.9499068165132434, 'support': 8697.0}, 'accuracy': 0.9410082468741686, 'macro avg': {'precision': 0.9428901876551959, 'recall': 0.9361739808228446, 'f1-score': 0.9390860406868684, 'support': 15036.0}, 'weighted avg': {'precision': 0.9414030508047729, 'recall': 0.9410082468741686, 'f1-score': 0.9407829939589216, 'support': 15036.0}} \n",
      "\n",
      "Aggregate metrics:  {'MCC': 0.8897086397503311, 'f1_macro': 0.9448405317681094, 'f1_micro': 0.9462623038042033, 'accuracy_balanced': 0.9443085753795242, 'accuracy': 0.9462623038042033, 'precision_macro': 0.9454007347091056, 'recall_macro': 0.9443085753795242, 'precision_micro': 0.9462623038042033, 'recall_micro': 0.9462623038042033}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikeb\\AppData\\Local\\Temp\\ipykernel_16576\\1338913006.py:27: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  labels, preds_max, labels=np.sort(pd.factorize(label_text_alphabetical, sort=True)[0]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed metrics:  {'entailment': {'precision': 0.9401559764443737, 'recall': 0.9318504495977283, 'f1-score': 0.9359847884645857, 'support': 6339.0}, 'not_entailment': {'precision': 0.9506454929738375, 'recall': 0.95676670116132, 'f1-score': 0.9536962750716332, 'support': 8697.0}, 'accuracy': 0.9462623038042033, 'macro avg': {'precision': 0.9454007347091056, 'recall': 0.9443085753795242, 'f1-score': 0.9448405317681094, 'support': 15036.0}, 'weighted avg': {'precision': 0.9462232367035347, 'recall': 0.9462623038042033, 'f1-score': 0.9462293215200188, 'support': 15036.0}} \n",
      "\n",
      "Aggregate metrics:  {'MCC': 0.8684692531945615, 'f1_macro': 0.9331477873712155, 'f1_micro': 0.9355546687948922, 'accuracy_balanced': 0.9286367983998921, 'accuracy': 0.9355546687948922, 'precision_macro': 0.9399055602318238, 'recall_macro': 0.9286367983998921, 'precision_micro': 0.9355546687948922, 'recall_micro': 0.9355546687948922}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikeb\\AppData\\Local\\Temp\\ipykernel_16576\\1338913006.py:27: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  labels, preds_max, labels=np.sort(pd.factorize(label_text_alphabetical, sort=True)[0]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed metrics:  {'entailment': {'precision': 0.9594455852156057, 'recall': 0.8845243729294842, 'f1-score': 0.9204629401625215, 'support': 6339.0}, 'not_entailment': {'precision': 0.9203655352480418, 'recall': 0.9727492238703, 'f1-score': 0.9458326345799094, 'support': 8697.0}, 'accuracy': 0.9355546687948922, 'macro avg': {'precision': 0.9399055602318238, 'recall': 0.9286367983998921, 'f1-score': 0.9331477873712155, 'support': 15036.0}, 'weighted avg': {'precision': 0.936841222714415, 'recall': 0.9355546687948922, 'f1-score': 0.9351370710715414, 'support': 15036.0}} \n",
      "\n",
      "Aggregate metrics:  {'MCC': 0.868220610524483, 'f1_macro': 0.933490332029201, 'f1_micro': 0.9356876828943868, 'accuracy_balanced': 0.9300563086171714, 'accuracy': 0.9356876828943868, 'precision_macro': 0.9382025175745834, 'recall_macro': 0.9300563086171714, 'precision_micro': 0.9356876828943868, 'recall_micro': 0.9356876828943868}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikeb\\AppData\\Local\\Temp\\ipykernel_16576\\1338913006.py:27: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  labels, preds_max, labels=np.sort(pd.factorize(label_text_alphabetical, sort=True)[0]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed metrics:  {'entailment': {'precision': 0.9503688799463448, 'recall': 0.8941473418520272, 'f1-score': 0.9214012842396163, 'support': 6339.0}, 'not_entailment': {'precision': 0.9260361552028219, 'recall': 0.9659652753823157, 'f1-score': 0.9455793798187855, 'support': 8697.0}, 'accuracy': 0.9356876828943868, 'macro avg': {'precision': 0.9382025175745834, 'recall': 0.9300563086171714, 'f1-score': 0.933490332029201, 'support': 15036.0}, 'weighted avg': {'precision': 0.9362945445450134, 'recall': 0.9356876828943868, 'f1-score': 0.9353861803058595, 'support': 15036.0}} \n",
      "\n",
      "Aggregate metrics:  {'MCC': 0.8824237243750158, 'f1_macro': 0.9410155574135199, 'f1_micro': 0.9427374301675978, 'accuracy_balanced': 0.939037434289971, 'accuracy': 0.9427374301675978, 'precision_macro': 0.9433970594097364, 'recall_macro': 0.939037434289971, 'precision_micro': 0.9427374301675978, 'recall_micro': 0.9427374301675978}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikeb\\AppData\\Local\\Temp\\ipykernel_16576\\1338913006.py:27: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  labels, preds_max, labels=np.sort(pd.factorize(label_text_alphabetical, sort=True)[0]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed metrics:  {'entailment': {'precision': 0.9469647519582245, 'recall': 0.9154440763527371, 'f1-score': 0.9309376754632229, 'support': 6339.0}, 'not_entailment': {'precision': 0.9398293668612483, 'recall': 0.9626307922272048, 'f1-score': 0.9510934393638171, 'support': 8697.0}, 'accuracy': 0.9427374301675978, 'macro avg': {'precision': 0.9433970594097364, 'recall': 0.939037434289971, 'f1-score': 0.9410155574135199, 'support': 15036.0}, 'weighted avg': {'precision': 0.9428375609374476, 'recall': 0.9427374301675978, 'f1-score': 0.9425960073761963, 'support': 15036.0}} \n",
      "\n",
      "Aggregate metrics:  {'MCC': 0.8880162279260374, 'f1_macro': 0.9439567629366055, 'f1_micro': 0.945464219207236, 'accuracy_balanced': 0.9429343397348423, 'accuracy': 0.945464219207236, 'precision_macro': 0.9450844912657135, 'recall_macro': 0.9429343397348423, 'precision_micro': 0.945464219207236, 'recall_micro': 0.945464219207236}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikeb\\AppData\\Local\\Temp\\ipykernel_16576\\1338913006.py:27: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  labels, preds_max, labels=np.sort(pd.factorize(label_text_alphabetical, sort=True)[0]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed metrics:  {'entailment': {'precision': 0.9428663135933237, 'recall': 0.9268023347531157, 'f1-score': 0.9347653142402546, 'support': 6339.0}, 'not_entailment': {'precision': 0.9473026689381033, 'recall': 0.9590663447165689, 'f1-score': 0.9531482116329563, 'support': 8697.0}, 'accuracy': 0.945464219207236, 'macro avg': {'precision': 0.9450844912657135, 'recall': 0.9429343397348423, 'f1-score': 0.9439567629366055, 'support': 15036.0}, 'weighted avg': {'precision': 0.94543235392543, 'recall': 0.945464219207236, 'f1-score': 0.9453981992245807, 'support': 15036.0}} \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#trainer.train(resume_from_checkpoint = 'training_base/checkpoint-157664')\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\sandbox\\Lib\\site-packages\\transformers\\trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1936\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1939\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\sandbox\\Lib\\site-packages\\transformers\\trainer.py:2284\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m   2279\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   2281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2282\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2283\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m-> 2284\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2285\u001b[0m ):\n\u001b[0;32m   2286\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2287\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[0;32m   2288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "#trainer.train(resume_from_checkpoint = 'training_base/checkpoint-157664')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7354294-8ffa-40f8-bb53-6493431392d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate metrics:  {'f1_macro': 0.9044187877129376, 'f1_micro': 0.9071485623003195, 'accuracy_balanced': 0.901032727240402, 'accuracy': 0.9071485623003195, 'precision_macro': 0.9096203014276345, 'recall_macro': 0.901032727240402, 'precision_micro': 0.9071485623003195, 'recall_micro': 0.9071485623003195}\n",
      "Detailed metrics:  {'entailment': {'precision': 0.9220152976388427, 'recall': 0.8569000154535621, 'f1-score': 0.8882659191029235, 'support': 6471.0}, 'not_entailment': {'precision': 0.8972253052164262, 'recall': 0.9451654390272419, 'f1-score': 0.9205716563229517, 'support': 8553.0}, 'accuracy': 0.9071485623003195, 'macro avg': {'precision': 0.9096203014276345, 'recall': 0.901032727240402, 'f1-score': 0.9044187877129376, 'support': 15024.0}, 'weighted avg': {'precision': 0.9079026242370237, 'recall': 0.9071485623003195, 'f1-score': 0.9066572243773445, 'support': 15024.0}} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikeb\\AppData\\Local\\Temp\\ipykernel_26668\\1657252757.py:25: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  labels, preds_max, labels=np.sort(pd.factorize(label_text_alphabetical, sort=True)[0]),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.1247555017471313,\n",
       " 'eval_f1_macro': 0.9044187877129376,\n",
       " 'eval_f1_micro': 0.9071485623003195,\n",
       " 'eval_accuracy_balanced': 0.901032727240402,\n",
       " 'eval_accuracy': 0.9071485623003195,\n",
       " 'eval_precision_macro': 0.9096203014276345,\n",
       " 'eval_recall_macro': 0.901032727240402,\n",
       " 'eval_precision_micro': 0.9071485623003195,\n",
       " 'eval_recall_micro': 0.9071485623003195}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset = dstok['test'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
